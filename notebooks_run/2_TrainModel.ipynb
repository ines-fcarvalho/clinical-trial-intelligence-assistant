{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "g-YGkdGd7OkY",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19167,
     "status": "ok",
     "timestamp": 1762512567222,
     "user": {
      "displayName": "Antonio Cortes",
      "userId": "07933854488654832685"
     },
     "user_tz": 0
    },
    "id": "g-YGkdGd7OkY",
    "outputId": "afef20e9-98d0-4174-99a5-27910d75c945"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63c963cb-5a6f-46ac-9042-7f287b9dfc20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [features] using feature_names_reduced_with_top_original.json\n",
      "\n",
      "==================================================\n",
      "  PHASE I – HINT TRAINING & VALIDATION\n",
      "==================================================\n",
      "\n",
      "  Python         : 3.11.11 on Darwin 22.6.0\n",
      "  XGBoost        : 3.0.5\n",
      "  Train matrix   : (5417, 1000)\n",
      "  Val matrix     : (1159, 1000)\n",
      "  Effective dims : 1000\n",
      "\n",
      "  [class weights]\n",
      "  alpha_neg       : 1.4\n",
      "  weight_neg (w0) : 4.880\n",
      "  weight_pos (w1) : 0.584\n",
      "\n",
      "  [tree_method] gpu_hist NOT available → using 'hist'.\n",
      "\n",
      "------------------------------------------\n",
      "  XGBOOST CONFIGURATION (PHASE TEMPLATE)\n",
      "------------------------------------------\n",
      "\n",
      "  tree_method      : hist\n",
      "  grow_policy      : lossguide\n",
      "  max_depth        : 4\n",
      "  max_leaves       : 64\n",
      "  learning_rate    : 0.03\n",
      "  total_trees      : 500\n",
      "  chunk_size       : 50\n",
      "  subsample        : 0.8\n",
      "  colsample_bytree : 0.7\n",
      "  reg_lambda (L2)  : 2.0\n",
      "  min_child_weight : 12\n",
      "  gamma            : 1.0\n",
      "  max_bin          : 256\n",
      "  bal_patience     : 3\n",
      "  target_TNR       : 0.8\n",
      "  random_state     : 42\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "  INCREMENTAL TRAINING (CHUNKED)\n",
      "----------------------------------------\n",
      "\n",
      "  → total_trees=500, chunk=50, max_leaves=64, lr=0.03, method=hist, min_child_weight=12\n",
      "\n",
      "  Chunk 01: trees 1..50 (add 50)\n",
      "   • AUC=0.7749 | PR-AUC=0.8834 | TNR=0.6627 | BalancedAcc=0.7269\n",
      "   ✓ New BEST (BalancedAcc): 0.7269 at trees=50\n",
      "\n",
      "  Chunk 02: trees 51..100 (add 50)\n",
      "   • AUC=0.7938 | PR-AUC=0.9087 | TNR=0.5422 | BalancedAcc=0.7425\n",
      "   ✓ New BEST (BalancedAcc): 0.7425 at trees=100\n",
      "\n",
      "  Chunk 03: trees 101..150 (add 50)\n",
      "   • AUC=0.7871 | PR-AUC=0.9017 | TNR=0.4900 | BalancedAcc=0.7307\n",
      "\n",
      "  Chunk 04: trees 151..200 (add 50)\n",
      "   • AUC=0.7760 | PR-AUC=0.8950 | TNR=0.5100 | BalancedAcc=0.7374\n",
      "\n",
      "  Chunk 05: trees 201..250 (add 50)\n",
      "   • AUC=0.7788 | PR-AUC=0.8947 | TNR=0.4900 | BalancedAcc=0.7290\n",
      "   Early stop: BalancedAcc plateau for 3 chunks.\n",
      "\n",
      "  Training loop finished.\n",
      "\n",
      "  ----------------------------------------\n",
      "  BEST CHECKPOINTS (VALIDATION – HINT)\n",
      "  ----------------------------------------\n",
      "  Best-by-AUC trees    : 100\n",
      "  Best Val AUC         : 0.79384\n",
      "  Best-by-BalAcc trees : 100\n",
      "  Best Val BalancedAcc : 0.74251\n",
      "\n",
      "   Checkpoints dir : /Users/antoniocortes/Tese/MyModel(hybrid)/xgb_model_package/phase_I/checkpoints\n",
      "   Loaded best booster (BalancedAcc): /Users/antoniocortes/Tese/MyModel(hybrid)/xgb_model_package/phase_I/checkpoints/xgb_best.json\n",
      "\n",
      "--------------------------------------------------------\n",
      "  VALIDATION SUMMARY – HINT (CALIBRATED PROBABILITIES)\n",
      "--------------------------------------------------------\n",
      "\n",
      "  --------------------------------------------------\n",
      "  VALIDATION @ THRESHOLD = 0.50 (HINT – Phase I)\n",
      "  --------------------------------------------------\n",
      "  AUROC        : 0.7938\n",
      "  AUPRC        : 0.9087\n",
      "  Accuracy     : 0.8637\n",
      "  Precision    : 0.8643\n",
      "  Recall (TPR) : 0.9802\n",
      "  F1           : 0.9186\n",
      "  TNR          : 0.4378\n",
      "  BalancedAcc  : 0.7090\n",
      "  TN, FP       : 109 , 140\n",
      "  FN, TP       : 18 , 892\n",
      "\n",
      "  Classification report (HINT validation, calibrated, thr=0.5):\n",
      "                precision    recall  f1-score   support\n",
      "  \n",
      "             0     0.8583    0.4378    0.5798       249\n",
      "             1     0.8643    0.9802    0.9186       910\n",
      "  \n",
      "      accuracy                         0.8637      1159\n",
      "     macro avg     0.8613    0.7090    0.7492      1159\n",
      "  weighted avg     0.8630    0.8637    0.8458      1159\n",
      "  \n",
      "\n",
      "-------------------------------------------------\n",
      "  VALIDATION @ TNR-CONSTRAINED THRESHOLD (HINT)\n",
      "-------------------------------------------------\n",
      "\n",
      "  --------------------------------------\n",
      "  TNR TARGET = 0.80 (HINT – Phase I)\n",
      "  --------------------------------------\n",
      "  Strategy note : TNR≥0.80\n",
      "  Chosen thr    : 0.876272\n",
      "  TNR           : 0.8072\n",
      "  TPR           : 0.4912\n",
      "  BalancedAcc   : 0.6492\n",
      "  AP (positive) : 0.9087\n",
      "  AP (negative) : 0.6882\n",
      "  TN, FP        : 201 , 48\n",
      "  FN, TP        : 463 , 447\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "  SAVING MODEL PACKAGE\n",
      "----------------------------------------\n",
      "\n",
      "  Saving model package to disk...\n",
      "\n",
      "  Saved phase package to: /Users/antoniocortes/Tese/MyModel(hybrid)/xgb_model_package/phase_I\n",
      "\n",
      "=== Model package artifacts (phase: phase_I): /Users/antoniocortes/Tese/MyModel(hybrid)/xgb_model_package ===\n",
      "\n",
      "  ── Phase: phase_I  →  /Users/antoniocortes/Tese/MyModel(hybrid)/xgb_model_package/phase_I\n",
      "     • phase_I/.ipynb_checkpoints/feature_importance_gain-checkpoint.json  | 29.5 KB  | mtime: 2025-11-07 14:55:18\n",
      "     • phase_I/.ipynb_checkpoints/feature_names-checkpoint.json  | 395.3 KB  | mtime: 2025-11-07 02:32:26\n",
      "     • phase_I/.ipynb_checkpoints/feature_names_reduced_with_top_original-checkpoint.json  | 46.3 KB  | mtime: 2025-11-07 02:33:48\n",
      "     • phase_I/checkpoints/train_trace.csv  | 4.6 KB  | mtime: 2025-12-09 15:04:08\n",
      "     • phase_I/checkpoints/train_trace.json  | 2.4 KB  | mtime: 2025-12-09 15:04:08\n",
      "     • phase_I/checkpoints/xgb_best.json  | 167.9 KB  | mtime: 2025-12-09 15:03:02\n",
      "     • phase_I/checkpoints/xgb_chunk.json  | 405.7 KB  | mtime: 2025-12-09 15:04:08\n",
      "     • phase_I/evals_result.json  | 12.7 KB  | mtime: 2025-12-09 15:04:09\n",
      "     • phase_I/feature_importance_by_origin.csv  | 0.6 KB  | mtime: 2025-11-17 18:46:57\n",
      "     • phase_I/feature_importance_gain.json  | 29.5 KB  | mtime: 2025-12-09 15:04:08\n",
      "     • phase_I/feature_names.json  | 395.3 KB  | mtime: 2025-11-07 02:32:26\n",
      "     • phase_I/feature_names_reduced_with_top_original.json  | 46.3 KB  | mtime: 2025-11-07 02:33:48\n",
      "     • phase_I/hint_xgb_model.joblib  | 150.1 KB  | mtime: 2025-12-09 15:04:08\n",
      "     • phase_I/model_metadata.json  | 1.9 KB  | mtime: 2025-12-09 15:04:09\n",
      "     • phase_I/prob_calibrator.joblib  | 0.9 KB  | mtime: 2025-12-09 15:04:08\n",
      "     • phase_I/svd_meta.json  | 0.8 KB  | mtime: 2025-11-07 02:33:48\n",
      "     • phase_I/xgb_model.json  | 167.9 KB  | mtime: 2025-12-09 15:04:08\n",
      "\n",
      "  >> Summary for Model package artifacts (phase: phase_I): 17 files, 1857.9 KB total\n",
      "  [features] using feature_names_reduced_with_top_original.json\n",
      "\n",
      "==================================================\n",
      "  PHASE II – HINT TRAINING & VALIDATION\n",
      "==================================================\n",
      "\n",
      "  Python         : 3.11.11 on Darwin 22.6.0\n",
      "  XGBoost        : 3.0.5\n",
      "  Train matrix   : (6761, 1000)\n",
      "  Val matrix     : (1452, 1000)\n",
      "  Effective dims : 1000\n",
      "\n",
      "  [class weights]\n",
      "  alpha_neg       : 1.4\n",
      "  weight_neg (w0) : 3.460\n",
      "  weight_pos (w1) : 0.627\n",
      "\n",
      "  [tree_method] gpu_hist NOT available → using 'hist'.\n",
      "\n",
      "------------------------------------------\n",
      "  XGBOOST CONFIGURATION (PHASE TEMPLATE)\n",
      "------------------------------------------\n",
      "\n",
      "  tree_method      : hist\n",
      "  grow_policy      : lossguide\n",
      "  max_depth        : 4\n",
      "  max_leaves       : 64\n",
      "  learning_rate    : 0.03\n",
      "  total_trees      : 500\n",
      "  chunk_size       : 50\n",
      "  subsample        : 0.8\n",
      "  colsample_bytree : 0.7\n",
      "  reg_lambda (L2)  : 2.0\n",
      "  min_child_weight : 12\n",
      "  gamma            : 1.0\n",
      "  max_bin          : 256\n",
      "  bal_patience     : 3\n",
      "  target_TNR       : 0.8\n",
      "  random_state     : 42\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "  INCREMENTAL TRAINING (CHUNKED)\n",
      "----------------------------------------\n",
      "\n",
      "  → total_trees=500, chunk=50, max_leaves=64, lr=0.03, method=hist, min_child_weight=12\n",
      "\n",
      "  Chunk 01: trees 1..50 (add 50)\n",
      "   • AUC=0.8336 | PR-AUC=0.9098 | TNR=0.7573 | BalancedAcc=0.7542\n",
      "   ✓ New BEST (BalancedAcc): 0.7542 at trees=50\n",
      "\n",
      "  Chunk 02: trees 51..100 (add 50)\n",
      "   • AUC=0.8419 | PR-AUC=0.9166 | TNR=0.7282 | BalancedAcc=0.7602\n",
      "   ✓ New BEST (BalancedAcc): 0.7602 at trees=100\n",
      "\n",
      "  Chunk 03: trees 101..150 (add 50)\n",
      "   • AUC=0.8414 | PR-AUC=0.9176 | TNR=0.7203 | BalancedAcc=0.7614\n",
      "   ✓ New BEST (BalancedAcc): 0.7614 at trees=150\n",
      "\n",
      "  Chunk 04: trees 151..200 (add 50)\n",
      "   • AUC=0.8410 | PR-AUC=0.9165 | TNR=0.7150 | BalancedAcc=0.7639\n",
      "   ✓ New BEST (BalancedAcc): 0.7639 at trees=200\n",
      "\n",
      "  Chunk 05: trees 201..250 (add 50)\n",
      "   • AUC=0.8393 | PR-AUC=0.9164 | TNR=0.7045 | BalancedAcc=0.7660\n",
      "   ✓ New BEST (BalancedAcc): 0.7660 at trees=250\n",
      "\n",
      "  Chunk 06: trees 251..300 (add 50)\n",
      "   • AUC=0.8382 | PR-AUC=0.9144 | TNR=0.6966 | BalancedAcc=0.7644\n",
      "\n",
      "  Chunk 07: trees 301..350 (add 50)\n",
      "   • AUC=0.8379 | PR-AUC=0.9146 | TNR=0.6939 | BalancedAcc=0.7650\n",
      "\n",
      "  Chunk 08: trees 351..400 (add 50)\n",
      "   • AUC=0.8377 | PR-AUC=0.9148 | TNR=0.6834 | BalancedAcc=0.7634\n",
      "   Early stop: BalancedAcc plateau for 3 chunks.\n",
      "\n",
      "  Training loop finished.\n",
      "\n",
      "  ----------------------------------------\n",
      "  BEST CHECKPOINTS (VALIDATION – HINT)\n",
      "  ----------------------------------------\n",
      "  Best-by-AUC trees    : 100\n",
      "  Best Val AUC         : 0.84188\n",
      "  Best-by-BalAcc trees : 250\n",
      "  Best Val BalancedAcc : 0.76604\n",
      "\n",
      "   Checkpoints dir : /Users/antoniocortes/Tese/MyModel(hybrid)/xgb_model_package/phase_II/checkpoints\n",
      "   Loaded best booster (BalancedAcc): /Users/antoniocortes/Tese/MyModel(hybrid)/xgb_model_package/phase_II/checkpoints/xgb_best.json\n",
      "\n",
      "--------------------------------------------------------\n",
      "  VALIDATION SUMMARY – HINT (CALIBRATED PROBABILITIES)\n",
      "--------------------------------------------------------\n",
      "\n",
      "  ---------------------------------------------------\n",
      "  VALIDATION @ THRESHOLD = 0.50 (HINT – Phase II)\n",
      "  ---------------------------------------------------\n",
      "  AUROC        : 0.8393\n",
      "  AUPRC        : 0.9164\n",
      "  Accuracy     : 0.8450\n",
      "  Precision    : 0.8643\n",
      "  Recall (TPR) : 0.9376\n",
      "  F1           : 0.8994\n",
      "  TNR          : 0.5831\n",
      "  BalancedAcc  : 0.7603\n",
      "  TN, FP       : 221 , 158\n",
      "  FN, TP       : 67 , 1006\n",
      "\n",
      "  Classification report (HINT validation, calibrated, thr=0.5):\n",
      "                precision    recall  f1-score   support\n",
      "  \n",
      "             0     0.7674    0.5831    0.6627       379\n",
      "             1     0.8643    0.9376    0.8994      1073\n",
      "  \n",
      "      accuracy                         0.8450      1452\n",
      "     macro avg     0.8158    0.7603    0.7810      1452\n",
      "  weighted avg     0.8390    0.8450    0.8376      1452\n",
      "  \n",
      "\n",
      "-------------------------------------------------\n",
      "  VALIDATION @ TNR-CONSTRAINED THRESHOLD (HINT)\n",
      "-------------------------------------------------\n",
      "\n",
      "  ---------------------------------------\n",
      "  TNR TARGET = 0.80 (HINT – Phase II)\n",
      "  ---------------------------------------\n",
      "  Strategy note : TNR≥0.80\n",
      "  Chosen thr    : 0.839224\n",
      "  TNR           : 0.8021\n",
      "  TPR           : 0.6943\n",
      "  BalancedAcc   : 0.7482\n",
      "  AP (positive) : 0.9164\n",
      "  AP (negative) : 0.7510\n",
      "  TN, FP        : 304 , 75\n",
      "  FN, TP        : 328 , 745\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "  SAVING MODEL PACKAGE\n",
      "----------------------------------------\n",
      "\n",
      "  Saving model package to disk...\n",
      "\n",
      "  Saved phase package to: /Users/antoniocortes/Tese/MyModel(hybrid)/xgb_model_package/phase_II\n",
      "\n",
      "=== Model package artifacts (phase: phase_II): /Users/antoniocortes/Tese/MyModel(hybrid)/xgb_model_package ===\n",
      "\n",
      "  ── Phase: phase_II  →  /Users/antoniocortes/Tese/MyModel(hybrid)/xgb_model_package/phase_II\n",
      "     • phase_II/.ipynb_checkpoints/feature_names_reduced_with_top_original-checkpoint.json  | 46.0 KB  | mtime: 2025-11-07 02:40:50\n",
      "     • phase_II/checkpoints/train_trace.csv  | 7.2 KB  | mtime: 2025-12-09 15:09:37\n",
      "     • phase_II/checkpoints/train_trace.json  | 3.9 KB  | mtime: 2025-12-09 15:09:37\n",
      "     • phase_II/checkpoints/xgb_best.json  | 416.8 KB  | mtime: 2025-12-09 15:06:48\n",
      "     • phase_II/checkpoints/xgb_chunk.json  | 659.1 KB  | mtime: 2025-12-09 15:09:37\n",
      "     • phase_II/evals_result.json  | 20.3 KB  | mtime: 2025-12-09 15:09:37\n",
      "     • phase_II/feature_importance_by_origin.csv  | 0.6 KB  | mtime: 2025-11-17 18:46:57\n",
      "     • phase_II/feature_importance_gain.json  | 52.8 KB  | mtime: 2025-12-09 15:09:37\n",
      "     • phase_II/feature_names.json  | 394.8 KB  | mtime: 2025-11-07 02:39:04\n",
      "     • phase_II/feature_names_reduced_with_top_original.json  | 46.0 KB  | mtime: 2025-11-07 02:40:50\n",
      "     • phase_II/hint_xgb_model.joblib  | 360.4 KB  | mtime: 2025-12-09 15:09:37\n",
      "     • phase_II/model_metadata.json  | 1.9 KB  | mtime: 2025-12-09 15:09:37\n",
      "     • phase_II/prob_calibrator.joblib  | 0.9 KB  | mtime: 2025-12-09 15:09:37\n",
      "     • phase_II/svd_meta.json  | 0.8 KB  | mtime: 2025-11-07 02:40:52\n",
      "     • phase_II/xgb_model.json  | 416.8 KB  | mtime: 2025-12-09 15:09:37\n",
      "\n",
      "  >> Summary for Model package artifacts (phase: phase_II): 15 files, 2428.3 KB total\n",
      "  [features] using feature_names_reduced_with_top_original.json\n",
      "\n",
      "==================================================\n",
      "  PHASE III – HINT TRAINING & VALIDATION\n",
      "==================================================\n",
      "\n",
      "  Python         : 3.11.11 on Darwin 22.6.0\n",
      "  XGBoost        : 3.0.5\n",
      "  Train matrix   : (4165, 1000)\n",
      "  Val matrix     : (894, 1000)\n",
      "  Effective dims : 1000\n",
      "\n",
      "  [class weights]\n",
      "  alpha_neg       : 1.4\n",
      "  weight_neg (w0) : 5.169\n",
      "  weight_pos (w1) : 0.578\n",
      "\n",
      "  [tree_method] gpu_hist NOT available → using 'hist'.\n",
      "\n",
      "------------------------------------------\n",
      "  XGBOOST CONFIGURATION (PHASE TEMPLATE)\n",
      "------------------------------------------\n",
      "\n",
      "  tree_method      : hist\n",
      "  grow_policy      : lossguide\n",
      "  max_depth        : 4\n",
      "  max_leaves       : 64\n",
      "  learning_rate    : 0.03\n",
      "  total_trees      : 500\n",
      "  chunk_size       : 50\n",
      "  subsample        : 0.8\n",
      "  colsample_bytree : 0.7\n",
      "  reg_lambda (L2)  : 2.0\n",
      "  min_child_weight : 12\n",
      "  gamma            : 1.0\n",
      "  max_bin          : 256\n",
      "  bal_patience     : 3\n",
      "  target_TNR       : 0.8\n",
      "  random_state     : 42\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "  INCREMENTAL TRAINING (CHUNKED)\n",
      "----------------------------------------\n",
      "\n",
      "  → total_trees=500, chunk=50, max_leaves=64, lr=0.03, method=hist, min_child_weight=12\n",
      "\n",
      "  Chunk 01: trees 1..50 (add 50)\n",
      "   • AUC=0.7433 | PR-AUC=0.8946 | TNR=0.7619 | BalancedAcc=0.6358\n",
      "   ✓ New BEST (BalancedAcc): 0.6358 at trees=50\n",
      "\n",
      "  Chunk 02: trees 51..100 (add 50)\n",
      "   • AUC=0.7402 | PR-AUC=0.8889 | TNR=0.6607 | BalancedAcc=0.6837\n",
      "   ✓ New BEST (BalancedAcc): 0.6837 at trees=100\n",
      "\n",
      "  Chunk 03: trees 101..150 (add 50)\n",
      "   • AUC=0.7423 | PR-AUC=0.8936 | TNR=0.5893 | BalancedAcc=0.6879\n",
      "   ✓ New BEST (BalancedAcc): 0.6879 at trees=150\n",
      "\n",
      "  Chunk 04: trees 151..200 (add 50)\n",
      "   • AUC=0.7403 | PR-AUC=0.8940 | TNR=0.5714 | BalancedAcc=0.7003\n",
      "   ✓ New BEST (BalancedAcc): 0.7003 at trees=200\n",
      "\n",
      "  Chunk 05: trees 201..250 (add 50)\n",
      "   • AUC=0.7362 | PR-AUC=0.8931 | TNR=0.5298 | BalancedAcc=0.6912\n",
      "\n",
      "  Chunk 06: trees 251..300 (add 50)\n",
      "   • AUC=0.7393 | PR-AUC=0.8970 | TNR=0.5357 | BalancedAcc=0.7017\n",
      "   ✓ New BEST (BalancedAcc): 0.7017 at trees=300\n",
      "\n",
      "  Chunk 07: trees 301..350 (add 50)\n",
      "   • AUC=0.7422 | PR-AUC=0.8965 | TNR=0.5298 | BalancedAcc=0.7077\n",
      "   ✓ New BEST (BalancedAcc): 0.7077 at trees=350\n",
      "\n",
      "  Chunk 08: trees 351..400 (add 50)\n",
      "   • AUC=0.7438 | PR-AUC=0.8999 | TNR=0.5238 | BalancedAcc=0.7171\n",
      "   ✓ New BEST (BalancedAcc): 0.7171 at trees=400\n",
      "\n",
      "  Chunk 09: trees 401..450 (add 50)\n",
      "   • AUC=0.7425 | PR-AUC=0.9000 | TNR=0.5238 | BalancedAcc=0.7220\n",
      "   ✓ New BEST (BalancedAcc): 0.7220 at trees=450\n",
      "\n",
      "  Chunk 10: trees 451..500 (add 50)\n",
      "   • AUC=0.7445 | PR-AUC=0.9011 | TNR=0.5000 | BalancedAcc=0.7087\n",
      "\n",
      "  Training loop finished.\n",
      "\n",
      "  ----------------------------------------\n",
      "  BEST CHECKPOINTS (VALIDATION – HINT)\n",
      "  ----------------------------------------\n",
      "  Best-by-AUC trees    : 500\n",
      "  Best Val AUC         : 0.74453\n",
      "  Best-by-BalAcc trees : 450\n",
      "  Best Val BalancedAcc : 0.72196\n",
      "\n",
      "   Checkpoints dir : /Users/antoniocortes/Tese/MyModel(hybrid)/xgb_model_package/phase_III/checkpoints\n",
      "   Loaded best booster (BalancedAcc): /Users/antoniocortes/Tese/MyModel(hybrid)/xgb_model_package/phase_III/checkpoints/xgb_best.json\n",
      "\n",
      "--------------------------------------------------------\n",
      "  VALIDATION SUMMARY – HINT (CALIBRATED PROBABILITIES)\n",
      "--------------------------------------------------------\n",
      "\n",
      "  ----------------------------------------------------\n",
      "  VALIDATION @ THRESHOLD = 0.50 (HINT – Phase III)\n",
      "  ----------------------------------------------------\n",
      "  AUROC        : 0.7425\n",
      "  AUPRC        : 0.9000\n",
      "  Accuracy     : 0.8770\n",
      "  Precision    : 0.8747\n",
      "  Recall (TPR) : 0.9904\n",
      "  F1           : 0.9289\n",
      "  TNR          : 0.3869\n",
      "  BalancedAcc  : 0.6886\n",
      "  TN, FP       : 65 , 103\n",
      "  FN, TP       : 7 , 719\n",
      "\n",
      "  Classification report (HINT validation, calibrated, thr=0.5):\n",
      "                precision    recall  f1-score   support\n",
      "  \n",
      "             0     0.9028    0.3869    0.5417       168\n",
      "             1     0.8747    0.9904    0.9289       726\n",
      "  \n",
      "      accuracy                         0.8770       894\n",
      "     macro avg     0.8887    0.6886    0.7353       894\n",
      "  weighted avg     0.8800    0.8770    0.8562       894\n",
      "  \n",
      "\n",
      "-------------------------------------------------\n",
      "  VALIDATION @ TNR-CONSTRAINED THRESHOLD (HINT)\n",
      "-------------------------------------------------\n",
      "\n",
      "  ----------------------------------------\n",
      "  TNR TARGET = 0.80 (HINT – Phase III)\n",
      "  ----------------------------------------\n",
      "  Strategy note : TNR≥0.80\n",
      "  Chosen thr    : 0.897122\n",
      "  TNR           : 0.8036\n",
      "  TPR           : 0.4339\n",
      "  BalancedAcc   : 0.6187\n",
      "  AP (positive) : 0.9000\n",
      "  AP (negative) : 0.6192\n",
      "  TN, FP        : 135 , 33\n",
      "  FN, TP        : 411 , 315\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "  SAVING MODEL PACKAGE\n",
      "----------------------------------------\n",
      "\n",
      "  Saving model package to disk...\n",
      "\n",
      "  Saved phase package to: /Users/antoniocortes/Tese/MyModel(hybrid)/xgb_model_package/phase_III\n",
      "\n",
      "=== Model package artifacts (phase: phase_III): /Users/antoniocortes/Tese/MyModel(hybrid)/xgb_model_package ===\n",
      "\n",
      "  ── Phase: phase_III  →  /Users/antoniocortes/Tese/MyModel(hybrid)/xgb_model_package/phase_III\n",
      "     • phase_III/checkpoints/train_trace.csv  | 8.6 KB  | mtime: 2025-12-09 15:14:17\n",
      "     • phase_III/checkpoints/train_trace.json  | 4.8 KB  | mtime: 2025-12-09 15:14:17\n",
      "     • phase_III/checkpoints/xgb_best.json  | 701.3 KB  | mtime: 2025-12-09 15:13:41\n",
      "     • phase_III/checkpoints/xgb_chunk.json  | 776.2 KB  | mtime: 2025-12-09 15:14:17\n",
      "     • phase_III/evals_result.json  | 25.3 KB  | mtime: 2025-12-09 15:14:17\n",
      "     • phase_III/feature_importance_by_origin.csv  | 0.6 KB  | mtime: 2025-11-17 18:46:57\n",
      "     • phase_III/feature_importance_gain.json  | 59.6 KB  | mtime: 2025-12-09 15:14:17\n",
      "     • phase_III/feature_names.json  | 332.8 KB  | mtime: 2025-11-07 02:45:04\n",
      "     • phase_III/feature_names_reduced_with_top_original.json  | 46.1 KB  | mtime: 2025-11-07 02:46:12\n",
      "     • phase_III/hint_xgb_model.joblib  | 613.3 KB  | mtime: 2025-12-09 15:14:17\n",
      "     • phase_III/model_metadata.json  | 1.9 KB  | mtime: 2025-12-09 15:14:17\n",
      "     • phase_III/prob_calibrator.joblib  | 0.9 KB  | mtime: 2025-12-09 15:14:17\n",
      "     • phase_III/svd_meta.json  | 0.8 KB  | mtime: 2025-11-07 02:46:12\n",
      "     • phase_III/xgb_model.json  | 701.3 KB  | mtime: 2025-12-09 15:14:17\n",
      "\n",
      "  >> Summary for Model package artifacts (phase: phase_III): 14 files, 3273.6 KB total\n",
      "\n",
      "==================================================\n",
      "  GLOBAL SUMMARY ACROSS PHASES (HINT VALIDATION)\n",
      "==================================================\n",
      "\n",
      "         Phase         |   AUC(best chunk)    |  BalAcc(best chunk)  | AUC(calibrated, thr=0.5) | BalAcc(calibrated, thr=0.5) |     TNR(thr=0.5)     |     Train shape      |      Val shape      \n",
      "  ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "        Phase I        |        0.7938        |        0.7425        |        0.7938        |        0.7090        |        0.4378        |     (5417, 1000)     |     (1159, 1000)    \n",
      "        Phase II       |        0.8419        |        0.7660        |        0.8393        |        0.7603        |        0.5831        |     (6761, 1000)     |     (1452, 1000)    \n",
      "       Phase III       |        0.7445        |        0.7220        |        0.7425        |        0.6886        |        0.3869        |     (4165, 1000)     |     (894, 1000)     \n",
      "\n",
      "\n",
      "=== All model package artifacts: /Users/antoniocortes/Tese/MyModel(hybrid)/xgb_model_package ===\n",
      "\n",
      "  ── Phase: phase_I  →  /Users/antoniocortes/Tese/MyModel(hybrid)/xgb_model_package/phase_I\n",
      "     • phase_I/.ipynb_checkpoints/feature_importance_gain-checkpoint.json  | 29.5 KB  | mtime: 2025-11-07 14:55:18\n",
      "     • phase_I/.ipynb_checkpoints/feature_names-checkpoint.json  | 395.3 KB  | mtime: 2025-11-07 02:32:26\n",
      "     • phase_I/.ipynb_checkpoints/feature_names_reduced_with_top_original-checkpoint.json  | 46.3 KB  | mtime: 2025-11-07 02:33:48\n",
      "     • phase_I/checkpoints/train_trace.csv  | 4.6 KB  | mtime: 2025-12-09 15:04:08\n",
      "     • phase_I/checkpoints/train_trace.json  | 2.4 KB  | mtime: 2025-12-09 15:04:08\n",
      "     • phase_I/checkpoints/xgb_best.json  | 167.9 KB  | mtime: 2025-12-09 15:03:02\n",
      "     • phase_I/checkpoints/xgb_chunk.json  | 405.7 KB  | mtime: 2025-12-09 15:04:08\n",
      "     • phase_I/evals_result.json  | 12.7 KB  | mtime: 2025-12-09 15:04:09\n",
      "     • phase_I/feature_importance_by_origin.csv  | 0.6 KB  | mtime: 2025-11-17 18:46:57\n",
      "     • phase_I/feature_importance_gain.json  | 29.5 KB  | mtime: 2025-12-09 15:04:08\n",
      "     • phase_I/feature_names.json  | 395.3 KB  | mtime: 2025-11-07 02:32:26\n",
      "     • phase_I/feature_names_reduced_with_top_original.json  | 46.3 KB  | mtime: 2025-11-07 02:33:48\n",
      "     • phase_I/hint_xgb_model.joblib  | 150.1 KB  | mtime: 2025-12-09 15:04:08\n",
      "     • phase_I/model_metadata.json  | 1.9 KB  | mtime: 2025-12-09 15:04:09\n",
      "     • phase_I/prob_calibrator.joblib  | 0.9 KB  | mtime: 2025-12-09 15:04:08\n",
      "     • phase_I/svd_meta.json  | 0.8 KB  | mtime: 2025-11-07 02:33:48\n",
      "     • phase_I/xgb_model.json  | 167.9 KB  | mtime: 2025-12-09 15:04:08\n",
      "\n",
      "  ── Phase: phase_II  →  /Users/antoniocortes/Tese/MyModel(hybrid)/xgb_model_package/phase_II\n",
      "     • phase_II/.ipynb_checkpoints/feature_names_reduced_with_top_original-checkpoint.json  | 46.0 KB  | mtime: 2025-11-07 02:40:50\n",
      "     • phase_II/checkpoints/train_trace.csv  | 7.2 KB  | mtime: 2025-12-09 15:09:37\n",
      "     • phase_II/checkpoints/train_trace.json  | 3.9 KB  | mtime: 2025-12-09 15:09:37\n",
      "     • phase_II/checkpoints/xgb_best.json  | 416.8 KB  | mtime: 2025-12-09 15:06:48\n",
      "     • phase_II/checkpoints/xgb_chunk.json  | 659.1 KB  | mtime: 2025-12-09 15:09:37\n",
      "     • phase_II/evals_result.json  | 20.3 KB  | mtime: 2025-12-09 15:09:37\n",
      "     • phase_II/feature_importance_by_origin.csv  | 0.6 KB  | mtime: 2025-11-17 18:46:57\n",
      "     • phase_II/feature_importance_gain.json  | 52.8 KB  | mtime: 2025-12-09 15:09:37\n",
      "     • phase_II/feature_names.json  | 394.8 KB  | mtime: 2025-11-07 02:39:04\n",
      "     • phase_II/feature_names_reduced_with_top_original.json  | 46.0 KB  | mtime: 2025-11-07 02:40:50\n",
      "     • phase_II/hint_xgb_model.joblib  | 360.4 KB  | mtime: 2025-12-09 15:09:37\n",
      "     • phase_II/model_metadata.json  | 1.9 KB  | mtime: 2025-12-09 15:09:37\n",
      "     • phase_II/prob_calibrator.joblib  | 0.9 KB  | mtime: 2025-12-09 15:09:37\n",
      "     • phase_II/svd_meta.json  | 0.8 KB  | mtime: 2025-11-07 02:40:52\n",
      "     • phase_II/xgb_model.json  | 416.8 KB  | mtime: 2025-12-09 15:09:37\n",
      "\n",
      "  ── Phase: phase_III  →  /Users/antoniocortes/Tese/MyModel(hybrid)/xgb_model_package/phase_III\n",
      "     • phase_III/checkpoints/train_trace.csv  | 8.6 KB  | mtime: 2025-12-09 15:14:17\n",
      "     • phase_III/checkpoints/train_trace.json  | 4.8 KB  | mtime: 2025-12-09 15:14:17\n",
      "     • phase_III/checkpoints/xgb_best.json  | 701.3 KB  | mtime: 2025-12-09 15:13:41\n",
      "     • phase_III/checkpoints/xgb_chunk.json  | 776.2 KB  | mtime: 2025-12-09 15:14:17\n",
      "     • phase_III/evals_result.json  | 25.3 KB  | mtime: 2025-12-09 15:14:17\n",
      "     • phase_III/feature_importance_by_origin.csv  | 0.6 KB  | mtime: 2025-11-17 18:46:57\n",
      "     • phase_III/feature_importance_gain.json  | 59.6 KB  | mtime: 2025-12-09 15:14:17\n",
      "     • phase_III/feature_names.json  | 332.8 KB  | mtime: 2025-11-07 02:45:04\n",
      "     • phase_III/feature_names_reduced_with_top_original.json  | 46.1 KB  | mtime: 2025-11-07 02:46:12\n",
      "     • phase_III/hint_xgb_model.joblib  | 613.3 KB  | mtime: 2025-12-09 15:14:17\n",
      "     • phase_III/model_metadata.json  | 1.9 KB  | mtime: 2025-12-09 15:14:17\n",
      "     • phase_III/prob_calibrator.joblib  | 0.9 KB  | mtime: 2025-12-09 15:14:17\n",
      "     • phase_III/svd_meta.json  | 0.8 KB  | mtime: 2025-11-07 02:46:12\n",
      "     • phase_III/xgb_model.json  | 701.3 KB  | mtime: 2025-12-09 15:14:17\n",
      "\n",
      "  >> Summary for All model package artifacts: 46 files, 7559.8 KB total\n"
     ]
    }
   ],
   "source": [
    "# =======================================================\n",
    "# HINT — Train XGBoost per phase (lossguide, chunked)\n",
    "# (aligned with latest Data-Transformation artifacts)\n",
    "# With: TNR-targeted threshold (default) + Platt calibration\n",
    "# =======================================================\n",
    "# Trains on per-phase, SVD-reduced matrices saved by the builder:\n",
    "#   /hint_xgb_artifacts/<phase>/\n",
    "# Saves model packages to:\n",
    "#   /xgb_model_package/<phase>/\n",
    "#\n",
    "# This version is reorganised to produce clean, well-structured\n",
    "# console reports, suitable for screenshots in the thesis:\n",
    "#  - Clear phase banners\n",
    "#  - Compact model configuration blocks\n",
    "#  - Validation summary tables\n",
    "#  - TNR-constrained threshold summary\n",
    "#  - Global cross-phase summary at the end\n",
    "# =======================================================\n",
    "\n",
    "from pathlib import Path\n",
    "import os, sys, json, time, csv, math, signal, platform, shutil\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import sparse as sp\n",
    "import joblib\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    classification_report, roc_auc_score, accuracy_score,\n",
    "    precision_recall_fscore_support, average_precision_score,\n",
    "    confusion_matrix, roc_curve\n",
    ")\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "# =======================================================\n",
    "# GLOBAL CONFIG\n",
    "# =======================================================\n",
    "\n",
    "ARTIFACTS_ROOT = Path(\"/Users/antoniocortes/Tese/MyModel(hybrid)/hint_xgb_artifacts\")\n",
    "MODEL_BASE     = Path(\"/Users/antoniocortes/Tese/MyModel(hybrid)/xgb_model_package\")\n",
    "\n",
    "# (Optional) per-phase preprocessor saved by the builder\n",
    "PREPROC_FILENAME_CANDIDATES = [\n",
    "    \"shared_preprocessor_hint_train.joblib\",\n",
    "    \"shared_blocks_hint_train.joblib\",\n",
    "    \"hint_preprocessor_train.joblib\",\n",
    "]\n",
    "\n",
    "# XGBoost knobs (conservative & comparable across phases)\n",
    "TOTAL_TREES   = 500\n",
    "CHUNK_SIZE    = 50\n",
    "LEARNING_RATE = 0.03\n",
    "MAX_LEAVES    = 64\n",
    "SUBSAMPLE     = 0.8\n",
    "COLSAMPLE     = 0.7\n",
    "REG_L2        = 2.0\n",
    "MIN_CHILD_W   = 12\n",
    "GAMMA         = 1.0\n",
    "MAX_BIN       = 256\n",
    "N_JOBS        = -1\n",
    "RANDOM_STATE  = 42\n",
    "\n",
    "# Optional per-phase overrides (small, safe nudges)\n",
    "PHASE_OVERRIDES = {\n",
    "    # \"phase_I\":  {\"min_child_weight\": 12},\n",
    "    # \"phase_II\": {\"min_child_weight\": 10},\n",
    "    # \"phase_III\":{\"min_child_weight\": 14},\n",
    "}\n",
    "\n",
    "# Early stop on BalancedAcc plateau (per chunk)\n",
    "BAL_PATIENCE           = 3\n",
    "BAL_IMPROVE_MIN_DELTA  = 1e-4\n",
    "\n",
    "# Class weighting\n",
    "ALPHA_NEG   = 1.4\n",
    "\n",
    "# Reporting threshold (now TNR-targeted by default)\n",
    "THRESHOLD   = 0.5\n",
    "TARGET_TNR  = 0.80   # <— enabled by default\n",
    "\n",
    "# Phase tags (as built for HINT)\n",
    "PHASES = [\"phase_I\", \"phase_II\", \"phase_III\"]\n",
    "\n",
    "# Preferred feature-name files (in order)\n",
    "FEATURE_NAME_PREFERENCE = [\n",
    "    \"feature_names_reduced_with_top_original.json\",\n",
    "    \"feature_names_reduced_with_prefix.json\",\n",
    "    \"feature_names_reduced.json\",\n",
    "    \"feature_names.json\",\n",
    "]\n",
    "\n",
    "# =======================================================\n",
    "# PRETTY PRINT HELPERS (for thesis-friendly logs)\n",
    "# =======================================================\n",
    "\n",
    "def banner(title: str, char: str = \"=\"):\n",
    "    line = char * max(len(title) + 4, 50)\n",
    "    print(\"\\n\" + line)\n",
    "    print(f\"  {title}\")\n",
    "    print(line + \"\\n\")\n",
    "\n",
    "def sub_banner(title: str, char: str = \"-\"):\n",
    "    line = char * max(len(title) + 4, 40)\n",
    "    print(\"\\n\" + line)\n",
    "    print(f\"  {title}\")\n",
    "    print(line + \"\\n\")\n",
    "\n",
    "def kv_block(pairs, indent: int = 2):\n",
    "    pad = \" \" * indent\n",
    "    max_key = max(len(k) for k, _ in pairs)\n",
    "    for k, v in pairs:\n",
    "        print(f\"{pad}{k:<{max_key}} : {v}\")\n",
    "    print()\n",
    "\n",
    "def metrics_table(title: str, rows, indent: int = 2):\n",
    "    \"\"\"\n",
    "    rows: list of (label, value_str)\n",
    "    \"\"\"\n",
    "    pad = \" \" * indent\n",
    "    max_label = max(len(lbl) for lbl, _ in rows)\n",
    "    print(f\"{pad}{'-' * (len(title) + 4)}\")\n",
    "    print(f\"{pad}{title}\")\n",
    "    print(f\"{pad}{'-' * (len(title) + 4)}\")\n",
    "    for lbl, val in rows:\n",
    "        print(f\"{pad}{lbl:<{max_label}} : {val}\")\n",
    "    print()\n",
    "\n",
    "# =======================================================\n",
    "# UTILS\n",
    "# =======================================================\n",
    "\n",
    "def _print_tree(root: Path, title: str, only_phase: str | None = None):\n",
    "    print(f\"\\n=== {title}: {root.resolve()} ===\")\n",
    "    if not root.exists():\n",
    "        print(\"  (directory not found)\")\n",
    "        return\n",
    "    total_files = 0\n",
    "    total_bytes = 0\n",
    "    phases = [only_phase] if only_phase else PHASES\n",
    "    for phase in phases:\n",
    "        phase_dir = root / phase\n",
    "        if not phase_dir.exists():\n",
    "            continue\n",
    "        print(f\"\\n  ── Phase: {phase}  →  {phase_dir.resolve()}\")\n",
    "        for path in sorted(phase_dir.rglob(\"*\")):\n",
    "            if path.is_file():\n",
    "                total_files += 1\n",
    "                size = path.stat().st_size\n",
    "                total_bytes += size\n",
    "                mtime = datetime.fromtimestamp(path.stat().st_mtime).isoformat(\n",
    "                    sep=' ', timespec='seconds'\n",
    "                )\n",
    "                rel = path.relative_to(root)\n",
    "                print(f\"     • {rel}  | {size/1024:.1f} KB  | mtime: {mtime}\")\n",
    "    print(f\"\\n  >> Summary for {title}: {total_files} files, {total_bytes/1024:.1f} KB total\")\n",
    "\n",
    "def _require(path: Path) -> Path:\n",
    "    if not path.exists():\n",
    "        raise FileNotFoundError(f\"Required file not found: {path}\")\n",
    "    return path\n",
    "\n",
    "def _find_first_existing(dir_path: Path, candidates: list[str]) -> Path | None:\n",
    "    for name in candidates:\n",
    "        p = dir_path / name\n",
    "        if p.exists():\n",
    "            return p\n",
    "    return None\n",
    "\n",
    "def pick_threshold_tnr_target(y_true, y_prob, target_tnr=0.80):\n",
    "    fpr, tpr, thr = roc_curve(y_true, y_prob)\n",
    "    tnr = 1.0 - fpr\n",
    "    idx_ok = np.where(tnr >= target_tnr)[0]\n",
    "    if len(idx_ok):\n",
    "        i = idx_ok[-1]\n",
    "        chosen = float(thr[i])\n",
    "        note = f\"TNR≥{target_tnr:.2f}\"\n",
    "    else:\n",
    "        i = int(np.lexsort((-tpr, tnr))[-1])\n",
    "        chosen = float(thr[i])\n",
    "        note = f\"TNR target {target_tnr:.2f} not reachable; picked best feasible (TNR={tnr[i]:.3f})\"\n",
    "    return chosen, dict(tpr=float(tpr[i]), tnr=float(tnr[i]), idx=int(i), note=note)\n",
    "\n",
    "def _load_feature_names_with_fallback(phase_dir: Path, n_expected: int) -> list[str]:\n",
    "    for fname in FEATURE_NAME_PREFERENCE:\n",
    "        p = phase_dir / fname\n",
    "        if p.exists():\n",
    "            try:\n",
    "                names = json.loads(p.read_text())\n",
    "                if len(names) == n_expected:\n",
    "                    print(f\"  [features] using {fname}\")\n",
    "                    return names\n",
    "            except Exception:\n",
    "                pass\n",
    "    print(\"  [features] no compatible name file found → using generic f0..fN\")\n",
    "    return [f\"f{i}\" for i in range(n_expected)]\n",
    "\n",
    "def _copy_if_exists(src_dir: Path, dst_dir: Path, filenames: list[str]):\n",
    "    dst_dir.mkdir(parents=True, exist_ok=True)\n",
    "    for name in filenames:\n",
    "        p = src_dir / name\n",
    "        if p.exists():\n",
    "            try:\n",
    "                shutil.copy2(p, dst_dir / name)\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "def _find_preprocessor(phase_dir: Path):\n",
    "    return _find_first_existing(phase_dir, PREPROC_FILENAME_CANDIDATES)\n",
    "\n",
    "def _load_reduced_split(phase_dir: Path, split: str) -> sp.csr_matrix:\n",
    "    fname_candidates = [\n",
    "        f\"X_{split}_reduced.npz\",\n",
    "        f\"X_{split[:3]}_reduced.npz\",\n",
    "    ]\n",
    "    for cand in fname_candidates:\n",
    "        p = phase_dir / cand\n",
    "        if p.exists():\n",
    "            return sp.load_npz(p)\n",
    "    p_fallback = phase_dir / f\"X_{split}.npz\"\n",
    "    if p_fallback.exists():\n",
    "        return sp.load_npz(p_fallback)\n",
    "    raise FileNotFoundError(f\"Reduced matrix for split='{split}' not found in {phase_dir}\")\n",
    "\n",
    "def load_phase_data(phase: str):\n",
    "    phase_dir = ARTIFACTS_ROOT / phase\n",
    "    X_train = _load_reduced_split(phase_dir, \"train\")\n",
    "    try:\n",
    "        X_val = _load_reduced_split(phase_dir, \"valid\")\n",
    "    except FileNotFoundError:\n",
    "        X_val = _load_reduced_split(phase_dir, \"val\")\n",
    "\n",
    "    y_train = np.load(_require(phase_dir / \"y_train.npy\"))\n",
    "    y_val = None\n",
    "    for cand in [\"y_valid.npy\", \"y_val.npy\"]:\n",
    "        p = phase_dir / cand\n",
    "        if p.exists():\n",
    "            y_val = np.load(p)\n",
    "            break\n",
    "    if y_val is None:\n",
    "        raise FileNotFoundError(f\"No validation labels found in {phase_dir}\")\n",
    "\n",
    "    feature_names = _load_feature_names_with_fallback(phase_dir, X_train.shape[1])\n",
    "\n",
    "    preproc_path = _find_preprocessor(phase_dir)\n",
    "    preprocessor = None\n",
    "    if preproc_path is not None:\n",
    "        try:\n",
    "            preprocessor = joblib.load(preproc_path)\n",
    "        except Exception:\n",
    "            preprocessor = None\n",
    "\n",
    "    svd_meta = {}\n",
    "    meta_file = phase_dir / \"svd_meta.json\"\n",
    "    if meta_file.exists():\n",
    "        try:\n",
    "            svd_meta = json.loads(meta_file.read_text())\n",
    "        except Exception:\n",
    "            svd_meta = {}\n",
    "\n",
    "    return X_train, X_val, y_train, y_val, feature_names, preprocessor, phase_dir, svd_meta\n",
    "\n",
    "def pick_tree_method_safe():\n",
    "    override = os.environ.get(\"XGB_TREE_METHOD\")\n",
    "    if override in {\"hist\", \"approx\", \"auto\", \"exact\", \"gpu_hist\"}:\n",
    "        print(f\"  [tree_method] using override: {override}\")\n",
    "        return override\n",
    "    try:\n",
    "        dm = xgb.DMatrix(sp.csr_matrix(np.array([[0.0]], dtype=np.float32)))\n",
    "        xgb.train(\n",
    "            params={\"tree_method\": \"gpu_hist\", \"max_depth\": 1, \"verbosity\": 0},\n",
    "            dtrain=dm,\n",
    "            num_boost_round=1,\n",
    "        )\n",
    "        print(\"  [tree_method] gpu_hist available.\")\n",
    "        return \"gpu_hist\"\n",
    "    except Exception:\n",
    "        print(\"  [tree_method] gpu_hist NOT available → using 'hist'.\")\n",
    "        return \"hist\"\n",
    "\n",
    "# =======================================================\n",
    "# TRAIN ONE PHASE\n",
    "# =======================================================\n",
    "\n",
    "def train_one_phase(phase: str):\n",
    "    # --- Load data & artifacts ---\n",
    "    X_train, X_val, y_train, y_val, feature_names, preprocessor, phase_dir, svd_meta = load_phase_data(phase)\n",
    "\n",
    "    # --- Prepare model dir ---\n",
    "    out_dir = MODEL_BASE / phase\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    chk_dir   = out_dir / \"checkpoints\"\n",
    "    chk_dir.mkdir(parents=True, exist_ok=True)\n",
    "    chk_path  = chk_dir / \"xgb_chunk.json\"\n",
    "    best_path = chk_dir / \"xgb_best.json\"\n",
    "    trace_json = chk_dir / \"train_trace.json\"\n",
    "    trace_csv  = chk_dir / \"train_trace.csv\"\n",
    "    stop_flag  = chk_dir / \"STOP.flag\"\n",
    "\n",
    "    # --- Phase banner ---\n",
    "    banner(f\"PHASE {phase.replace('phase_', '').upper()} – HINT TRAINING & VALIDATION\")\n",
    "\n",
    "    # --- Print environment & data info ---\n",
    "    kv_block([\n",
    "        (\"Python\",        f\"{sys.version.split()[0]} on {platform.system()} {platform.release()}\"),\n",
    "        (\"XGBoost\",       xgb.__version__),\n",
    "        (\"Train matrix\",  f\"{X_train.shape}\"),\n",
    "        (\"Val matrix\",    f\"{X_val.shape}\"),\n",
    "        (\"Effective dims\", svd_meta.get(\"global_cap_effective\", X_train.shape[1])),\n",
    "    ])\n",
    "\n",
    "    # --- Class-balanced sample weights (NEG boosted) ---\n",
    "    classes = np.array([0, 1])\n",
    "    class_w = compute_class_weight(class_weight=\"balanced\", classes=classes, y=y_train)\n",
    "    w0, w1 = float(class_w[0]) * ALPHA_NEG, float(class_w[1])\n",
    "    print(\"  [class weights]\")\n",
    "    kv_block([\n",
    "        (\"alpha_neg\",       ALPHA_NEG),\n",
    "        (\"weight_neg (w0)\", f\"{w0:.3f}\"),\n",
    "        (\"weight_pos (w1)\", f\"{w1:.3f}\"),\n",
    "    ])\n",
    "\n",
    "    # --- CSV header for detailed trace (if needed later) ---\n",
    "    if not trace_csv.exists():\n",
    "        with open(trace_csv, \"w\", newline=\"\") as f:\n",
    "            csv.writer(f).writerow(\n",
    "                [\"chunk\",\"trees\",\"val_auc\",\"val_pr_auc\",\n",
    "                 \"acc\",\"prec\",\"rec\",\"f1\",\n",
    "                 \"cm_tn\",\"cm_fp\",\"cm_fn\",\"cm_tp\",\n",
    "                 \"auc_delta\",\"elapsed_min\",\"chunk_min\",\"eta_total_min\",\n",
    "                 \"note\"]\n",
    "            )\n",
    "\n",
    "    # --- Choose tree_method ---\n",
    "    tree_method = pick_tree_method_safe()\n",
    "\n",
    "    # --- Per-phase overrides ---\n",
    "    ov = PHASE_OVERRIDES.get(phase, {})\n",
    "\n",
    "    # --- Model definition ---\n",
    "    model = XGBClassifier(\n",
    "        tree_method=tree_method,\n",
    "        grow_policy=\"lossguide\",\n",
    "        max_leaves=MAX_LEAVES,\n",
    "        max_depth=4,\n",
    "        n_estimators=0,\n",
    "        learning_rate=LEARNING_RATE,\n",
    "        subsample=SUBSAMPLE,\n",
    "        colsample_bytree=COLSAMPLE,\n",
    "        reg_lambda=REG_L2,\n",
    "        reg_alpha=0.0,\n",
    "        min_child_weight=ov.get(\"min_child_weight\", MIN_CHILD_W),\n",
    "        gamma=GAMMA,\n",
    "        max_bin=MAX_BIN,\n",
    "        objective=\"binary:logistic\",\n",
    "        eval_metric=[\"aucpr\",\"auc\"],\n",
    "        n_jobs=N_JOBS,\n",
    "        random_state=RANDOM_STATE,\n",
    "        scale_pos_weight=1.0,\n",
    "        max_delta_step=1,\n",
    "    )\n",
    "\n",
    "    # --- Print compact configuration block (good for thesis screenshot) ---\n",
    "    sub_banner(\"XGBOOST CONFIGURATION (PHASE TEMPLATE)\")\n",
    "    kv_block([\n",
    "        (\"tree_method\",       tree_method),\n",
    "        (\"grow_policy\",       \"lossguide\"),\n",
    "        (\"max_depth\",         4),\n",
    "        (\"max_leaves\",        MAX_LEAVES),\n",
    "        (\"learning_rate\",     LEARNING_RATE),\n",
    "        (\"total_trees\",       TOTAL_TREES),\n",
    "        (\"chunk_size\",        CHUNK_SIZE),\n",
    "        (\"subsample\",         SUBSAMPLE),\n",
    "        (\"colsample_bytree\",  COLSAMPLE),\n",
    "        (\"reg_lambda (L2)\",   REG_L2),\n",
    "        (\"min_child_weight\",  model.get_params()[\"min_child_weight\"]),\n",
    "        (\"gamma\",             GAMMA),\n",
    "        (\"max_bin\",           MAX_BIN),\n",
    "        (\"bal_patience\",      BAL_PATIENCE),\n",
    "        (\"target_TNR\",        TARGET_TNR),\n",
    "        (\"random_state\",      RANDOM_STATE),\n",
    "    ])\n",
    "\n",
    "    # --- Training loop (chunked) ---\n",
    "    start_time = time.time()\n",
    "    trained_trees = 0\n",
    "    best_auc = -np.inf\n",
    "    best_bal_acc = -np.inf\n",
    "    best_trees_auc = 0\n",
    "    best_trees_bal = 0\n",
    "    last_auc = None\n",
    "    chunk_index = 0\n",
    "    bal_no_improve = 0\n",
    "    trace = []\n",
    "\n",
    "    def _elapsed_min():\n",
    "        return (time.time() - start_time) / 60.0\n",
    "\n",
    "    def _handle_sigint(sig, frame):\n",
    "        print(\"\\n Interrupt received. Will stop after this chunk (checkpoint saved).\")\n",
    "        raise KeyboardInterrupt()\n",
    "    signal.signal(signal.SIGINT, _handle_sigint)\n",
    "\n",
    "    sub_banner(\"INCREMENTAL TRAINING (CHUNKED)\")\n",
    "    print(f\"  → total_trees={TOTAL_TREES}, chunk={CHUNK_SIZE}, max_leaves={MAX_LEAVES}, \"\n",
    "          f\"lr={LEARNING_RATE}, method={tree_method}, min_child_weight={model.get_params()['min_child_weight']}\")\n",
    "\n",
    "    try:\n",
    "        while trained_trees < TOTAL_TREES:\n",
    "            if stop_flag.exists():\n",
    "                print(\"  STOP.flag detected. Ending after this chunk.\")\n",
    "            next_target = min(trained_trees + CHUNK_SIZE, TOTAL_TREES)\n",
    "            add_trees = next_target - trained_trees\n",
    "            chunk_index += 1\n",
    "            print(f\"\\n  Chunk {chunk_index:02d}: trees {trained_trees + 1}..{next_target} (add {add_trees})\")\n",
    "\n",
    "            t0 = time.time()\n",
    "            model.set_params(n_estimators=next_target)\n",
    "            model.fit(\n",
    "                X_train, y_train,\n",
    "                sample_weight=np.where(y_train == 0, w0, w1),\n",
    "                eval_set=[(X_val, y_val)],\n",
    "                verbose=False\n",
    "            )\n",
    "\n",
    "            # Save checkpoint\n",
    "            model.get_booster().save_model(str(chk_path))\n",
    "            trained_trees = next_target\n",
    "\n",
    "            # ---- Per-chunk validation metrics (raw scores) ----\n",
    "            proba_val_raw = model.predict_proba(X_val)[:, 1]\n",
    "            pred_val_raw  = (proba_val_raw >= THRESHOLD).astype(int)\n",
    "\n",
    "            auc  = roc_auc_score(y_val, proba_val_raw)\n",
    "            ap   = average_precision_score(y_val, proba_val_raw)\n",
    "            acc  = accuracy_score(y_val, pred_val_raw)\n",
    "            prec, rec, f1, _ = precision_recall_fscore_support(\n",
    "                y_val, pred_val_raw, average=\"binary\", zero_division=0)\n",
    "\n",
    "            tn, fp, fn, tp = confusion_matrix(y_val, pred_val_raw).ravel()\n",
    "            tnr = tn / (tn + fp + 1e-9)\n",
    "            tpr = tp / (tp + fn + 1e-9)\n",
    "            bal_acc = 0.5 * (tpr + tnr)\n",
    "\n",
    "            print(f\"   • AUC={auc:.4f} | PR-AUC={ap:.4f} | TNR={tnr:.4f} | BalancedAcc={bal_acc:.4f}\")\n",
    "\n",
    "            # Track best-by-AUC\n",
    "            auc_delta = auc - last_auc if last_auc is not None else None\n",
    "            if auc > best_auc + 1e-9:\n",
    "                best_auc = auc\n",
    "                best_trees_auc = trained_trees\n",
    "            last_auc = auc\n",
    "\n",
    "            # Keep best-by-BalAcc\n",
    "            if bal_acc > best_bal_acc + BAL_IMPROVE_MIN_DELTA:\n",
    "                best_bal_acc = float(bal_acc)\n",
    "                best_trees_bal = int(trained_trees)\n",
    "                model.get_booster().save_model(str(best_path))\n",
    "                print(f\"   ✓ New BEST (BalancedAcc): {best_bal_acc:.4f} at trees={best_trees_bal}\")\n",
    "                bal_no_improve = 0\n",
    "            else:\n",
    "                bal_no_improve += 1\n",
    "\n",
    "            chunk_min = (time.time() - t0) / 60.0\n",
    "            elapsed_min = _elapsed_min()\n",
    "            chunks_done = math.ceil(trained_trees / CHUNK_SIZE)\n",
    "            chunks_total = math.ceil(TOTAL_TREES / CHUNK_SIZE)\n",
    "            avg_per_chunk = (elapsed_min / max(1, chunks_done))\n",
    "            eta_total_min = avg_per_chunk * chunks_total\n",
    "\n",
    "            # log CSV/JSON\n",
    "            entry = {\n",
    "                \"chunk\": chunk_index, \"trees\": trained_trees,\n",
    "                \"val_auc\": float(auc), \"val_pr_auc\": float(ap),\n",
    "                \"acc\": float(acc), \"prec\": float(prec), \"rec\": float(rec), \"f1\": float(f1),\n",
    "                \"cm_tn\": int(tn), \"cm_fp\": int(fp), \"cm_fn\": int(fn), \"cm_tp\": int(tp),\n",
    "                \"auc_delta\": float(auc_delta) if auc_delta is not None else None,\n",
    "                \"elapsed_min\": float(elapsed_min), \"chunk_min\": float(chunk_min),\n",
    "                \"eta_total_min\": float(eta_total_min),\n",
    "                \"note\": f\"best_bal={best_bal_acc:.4f} at {best_trees_bal}\"\n",
    "            }\n",
    "            trace.append(entry)\n",
    "            with open(trace_json, \"w\") as f:\n",
    "                json.dump(trace, f, indent=2)\n",
    "            with open(trace_csv, \"a\", newline=\"\") as f:\n",
    "                csv.writer(f).writerow([\n",
    "                    entry[\"chunk\"], entry[\"trees\"], entry[\"val_auc\"], entry[\"val_pr_auc\"],\n",
    "                    entry[\"acc\"], entry[\"prec\"], entry[\"rec\"], entry[\"f1\"],\n",
    "                    entry[\"cm_tn\"], entry[\"cm_fp\"], entry[\"cm_fn\"], entry[\"cm_tp\"],\n",
    "                    entry[\"auc_delta\"], entry[\"elapsed_min\"], entry[\"chunk_min\"], entry[\"eta_total_min\"],\n",
    "                    entry[\"note\"]\n",
    "                ])\n",
    "\n",
    "            # plateau early-stop\n",
    "            if BAL_PATIENCE and bal_no_improve >= BAL_PATIENCE:\n",
    "                print(f\"   Early stop: BalancedAcc plateau for {BAL_PATIENCE} chunks.\")\n",
    "                break\n",
    "\n",
    "            if stop_flag.exists():\n",
    "                print(\"   STOP.flag honored. Ending now (checkpoint saved).\")\n",
    "                break\n",
    "\n",
    "        print(\"\\n  Training loop finished.\")\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(f\"\\n  ⏸ Paused at trees={trained_trees}. Checkpoint at: {chk_path}\")\n",
    "\n",
    "    print()\n",
    "    metrics_table(\n",
    "        \"BEST CHECKPOINTS (VALIDATION – HINT)\",\n",
    "        [\n",
    "            (\"Best-by-AUC trees\",     f\"{best_trees_auc}\"),\n",
    "            (\"Best Val AUC\",          f\"{best_auc:.5f}\"),\n",
    "            (\"Best-by-BalAcc trees\",  f\"{best_trees_bal}\"),\n",
    "            (\"Best Val BalancedAcc\",  f\"{best_bal_acc:.5f}\"),\n",
    "        ],\n",
    "        indent=2,\n",
    "    )\n",
    "    print(f\"   Checkpoints dir : {chk_dir}\")\n",
    "\n",
    "    # Load best booster (BalancedAcc) for final eval\n",
    "    if best_path.exists():\n",
    "        booster = xgb.Booster()\n",
    "        booster.load_model(str(best_path))\n",
    "        model._Booster = booster\n",
    "        print(f\"   Loaded best booster (BalancedAcc): {best_path}\")\n",
    "\n",
    "    # ---- Final eval @ calibrated scores ----\n",
    "    sub_banner(\"VALIDATION SUMMARY – HINT (CALIBRATED PROBABILITIES)\")\n",
    "\n",
    "    proba_val_raw = model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "    # Post-hoc calibration (Platt) on validation\n",
    "    platt = LogisticRegression(max_iter=1000)\n",
    "    platt.fit(proba_val_raw.reshape(-1, 1), y_val)\n",
    "\n",
    "    def apply_calibrated(p_raw: np.ndarray) -> np.ndarray:\n",
    "        return platt.predict_proba(p_raw.reshape(-1, 1))[:, 1]\n",
    "\n",
    "    proba_val_cal = apply_calibrated(proba_val_raw)\n",
    "\n",
    "    # Use calibrated scores for final validation metrics @ default threshold\n",
    "    proba_for_eval = proba_val_cal\n",
    "    pred_val  = (proba_for_eval >= THRESHOLD).astype(int)\n",
    "\n",
    "    auc  = roc_auc_score(y_val, proba_for_eval)\n",
    "    ap   = average_precision_score(y_val, proba_for_eval)\n",
    "    acc  = accuracy_score(y_val, pred_val)\n",
    "    prec, rec, f1, _ = precision_recall_fscore_support(\n",
    "        y_val, pred_val, average=\"binary\", zero_division=0)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_val, pred_val).ravel()\n",
    "    tnr = tn / (tn + fp + 1e-9)\n",
    "    tpr = tp / (tp + fn + 1e-9)\n",
    "    bal_acc = 0.5 * (tpr + tnr)\n",
    "\n",
    "    # Compact summary block – PERFECT for a screenshot in 6.3/6.4\n",
    "    metrics_table(\n",
    "        f\"VALIDATION @ THRESHOLD = 0.50 (HINT – {phase.replace('phase_', 'Phase ')})\",\n",
    "        [\n",
    "            (\"AUROC\",        f\"{auc:.4f}\"),\n",
    "            (\"AUPRC\",        f\"{ap:.4f}\"),\n",
    "            (\"Accuracy\",     f\"{acc:.4f}\"),\n",
    "            (\"Precision\",    f\"{prec:.4f}\"),\n",
    "            (\"Recall (TPR)\", f\"{rec:.4f}\"),\n",
    "            (\"F1\",           f\"{f1:.4f}\"),\n",
    "            (\"TNR\",          f\"{tnr:.4f}\"),\n",
    "            (\"BalancedAcc\",  f\"{bal_acc:.4f}\"),\n",
    "            (\"TN, FP\",       f\"{tn} , {fp}\"),\n",
    "            (\"FN, TP\",       f\"{fn} , {tp}\"),\n",
    "        ],\n",
    "        indent=2,\n",
    "    )\n",
    "\n",
    "    print(\"  Classification report (HINT validation, calibrated, thr=0.5):\")\n",
    "    print(\"  \" + classification_report(y_val, pred_val, digits=4).replace(\"\\n\", \"\\n  \"))\n",
    "\n",
    "    # Optional (default ON): tune threshold to TNR target using calibrated scores\n",
    "    tuned = None\n",
    "    if TARGET_TNR is not None:\n",
    "        thr, info = pick_threshold_tnr_target(y_val, proba_for_eval, target_tnr=TARGET_TNR)\n",
    "        pred_tuned = (proba_for_eval >= thr).astype(int)\n",
    "        tn2, fp2, fn2, tp2 = confusion_matrix(y_val, pred_tuned).ravel()\n",
    "        tpr_ = tp2 / (tp2 + fn2 + 1e-9)\n",
    "        tnr_ = tn2 / (tn2 + fp2 + 1e-9)\n",
    "        bal_acc_ = 0.5 * (tpr_ + tnr_)\n",
    "        ap_pos = average_precision_score(y_val, proba_for_eval)\n",
    "        ap_neg = average_precision_score(y_val, 1 - proba_for_eval, pos_label=0)\n",
    "\n",
    "        sub_banner(\"VALIDATION @ TNR-CONSTRAINED THRESHOLD (HINT)\")\n",
    "\n",
    "        metrics_table(\n",
    "            f\"TNR TARGET = {TARGET_TNR:.2f} (HINT – {phase.replace('phase_', 'Phase ')})\",\n",
    "            [\n",
    "                (\"Strategy note\",   info[\"note\"]),\n",
    "                (\"Chosen thr\",      f\"{thr:.6f}\"),\n",
    "                (\"TNR\",             f\"{tnr_:.4f}\"),\n",
    "                (\"TPR\",             f\"{tpr_:.4f}\"),\n",
    "                (\"BalancedAcc\",     f\"{bal_acc_:.4f}\"),\n",
    "                (\"AP (positive)\",   f\"{ap_pos:.4f}\"),\n",
    "                (\"AP (negative)\",   f\"{ap_neg:.4f}\"),\n",
    "                (\"TN, FP\",          f\"{tn2} , {fp2}\"),\n",
    "                (\"FN, TP\",          f\"{fn2} , {tp2}\"),\n",
    "            ],\n",
    "            indent=2,\n",
    "        )\n",
    "\n",
    "        tuned = {\"threshold\": float(thr), **info, \"bal_acc\": float(bal_acc_)}\n",
    "\n",
    "    # --- Save package per phase ---\n",
    "    sub_banner(\"SAVING MODEL PACKAGE\")\n",
    "    print(\"  Saving model package to disk...\")\n",
    "\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Save sklearn wrapper\n",
    "    joblib.dump(model, out_dir / \"hint_xgb_model.joblib\")\n",
    "    # Save booster JSON\n",
    "    model.save_model(str(out_dir / \"xgb_model.json\"))\n",
    "    # Save calibrator\n",
    "    joblib.dump(platt, out_dir / \"prob_calibrator.joblib\")\n",
    "\n",
    "    # Save pipeline (preprocessor + model) if available (for provenance)\n",
    "    if preprocessor is not None:\n",
    "        joblib.dump(\n",
    "            {\"preprocessor\": preprocessor, \"model\": model, \"calibrator\": platt},\n",
    "            out_dir / \"hint_pipeline_full.joblib\"\n",
    "        )\n",
    "\n",
    "    # Save feature importance by gain (use reduced feature names)\n",
    "    booster = model.get_booster()\n",
    "    importance = booster.get_score(importance_type=\"gain\")\n",
    "    feat_imp = {}\n",
    "    for k, v in importance.items():\n",
    "        try:\n",
    "            idx = int(k[1:])  # f0, f1, ...\n",
    "            fname = feature_names[idx] if idx < len(feature_names) else k\n",
    "        except Exception:\n",
    "            fname = k\n",
    "        feat_imp[fname] = float(v)\n",
    "    with open(out_dir / \"feature_importance_gain.json\", \"w\") as f:\n",
    "        json.dump(feat_imp, f, indent=2)\n",
    "\n",
    "    # Write feature-name files into the model package dir (copy any that exist)\n",
    "    name_files_to_copy = [\n",
    "        \"feature_names_reduced_with_top_original.json\",\n",
    "        \"feature_names_reduced_with_prefix.json\",\n",
    "        \"feature_names_reduced.json\",\n",
    "        \"feature_names.json\",\n",
    "        \"svd_meta.json\",\n",
    "        \"preprocessor_meta.json\",\n",
    "    ]\n",
    "    _copy_if_exists(phase_dir, out_dir, name_files_to_copy)\n",
    "\n",
    "    # Save evals_result & metadata\n",
    "    try:\n",
    "        evals_result = model.evals_result()\n",
    "    except Exception:\n",
    "        evals_result = {}\n",
    "    with open(out_dir / \"evals_result.json\", \"w\") as f:\n",
    "        json.dump(evals_result, f, indent=2)\n",
    "\n",
    "    meta = {\n",
    "        \"phase\": phase,\n",
    "        \"framework\": \"xgboost\",\n",
    "        \"growth_policy\": \"lossguide\",\n",
    "        \"n_features\": int(X_train.shape[1]),\n",
    "        \"n_train_samples\": int(X_train.shape[0]),\n",
    "        \"n_val_samples\": int(X_val.shape[0]),\n",
    "        \"random_state\": RANDOM_STATE,\n",
    "        \"class_weighting\": {\"alpha_neg\": ALPHA_NEG, \"computed_w0\": float(w0), \"computed_w1\": float(w1)},\n",
    "        \"best_chunk_trees_auc\": int(best_trees_auc),\n",
    "        \"best_val_auc\": float(best_auc),\n",
    "        \"best_chunk_trees_bal\": int(best_trees_bal),\n",
    "        \"best_val_bal_acc\": float(best_bal_acc),\n",
    "        \"training\": {\n",
    "            \"total_trees\": TOTAL_TREES,\n",
    "            \"chunk_size\": CHUNK_SIZE,\n",
    "            \"learning_rate\": LEARNING_RATE,\n",
    "            \"max_leaves\": MAX_LEAVES,\n",
    "            \"subsample\": SUBSAMPLE,\n",
    "            \"colsample_bytree\": COLSAMPLE,\n",
    "            \"reg_lambda\": REG_L2,\n",
    "            \"reg_alpha\": 0.0,\n",
    "            \"min_child_weight\": int(model.get_params()[\"min_child_weight\"]),\n",
    "            \"gamma\": GAMMA,\n",
    "            \"max_bin\": MAX_BIN,\n",
    "            \"n_jobs\": N_JOBS,\n",
    "            \"bal_patience\": BAL_PATIENCE,\n",
    "            \"target_tnr\": TARGET_TNR,\n",
    "        },\n",
    "        \"artifacts_used\": {\n",
    "            \"data_dir\": str(phase_dir),\n",
    "            \"feature_names_source\": \"preferred by order: \" + \" → \".join(FEATURE_NAME_PREFERENCE),\n",
    "            \"best_booster_json\": str(best_path.relative_to(out_dir)) if best_path.exists() else None,\n",
    "            \"last_checkpoint_json\": str(chk_path.relative_to(out_dir)) if chk_path.exists() else None,\n",
    "            \"trace_json\": str(trace_json.relative_to(out_dir)),\n",
    "            \"trace_csv\": str(trace_csv.relative_to(out_dir)),\n",
    "        },\n",
    "        \"inference_threshold\": (\n",
    "            {\"strategy\": \"tnr_target\", **tuned} if tuned is not None\n",
    "            else {\"strategy\": \"fixed\", \"threshold\": THRESHOLD}\n",
    "        ),\n",
    "        \"calibration\": {\"type\": \"platt\", \"fitted_on\": \"validation\", \"file\": \"prob_calibrator.joblib\"},\n",
    "        \"files\": {\n",
    "            \"sklearn_joblib\": \"hint_xgb_model.joblib\",\n",
    "            \"xgb_json\": \"xgb_model.json\",\n",
    "            \"pipeline_full\": \"hint_pipeline_full.joblib\" if preprocessor is not None else None,\n",
    "            \"feature_importance_gain\": \"feature_importance_gain.json\",\n",
    "            \"evals_result\": \"evals_result.json\",\n",
    "            \"model_metadata\": \"model_metadata.json\",\n",
    "            \"prob_calibrator\": \"prob_calibrator.joblib\",\n",
    "        },\n",
    "    }\n",
    "    with open(out_dir / \"model_metadata.json\", \"w\") as f:\n",
    "        json.dump(meta, f, indent=2)\n",
    "\n",
    "    print(f\"\\n  Saved phase package to: {out_dir}\")\n",
    "    _print_tree(MODEL_BASE, f\"Model package artifacts (phase: {phase})\", only_phase=phase)\n",
    "\n",
    "    return {\n",
    "        \"phase\": phase,\n",
    "        \"best_auc\": best_auc,\n",
    "        \"best_bal_acc\": best_bal_acc,\n",
    "        \"val_auc_calibrated\": auc,\n",
    "        \"val_balacc_calibrated\": bal_acc,\n",
    "        \"train_shape\": tuple(X_train.shape),\n",
    "        \"val_shape\": tuple(X_val.shape),\n",
    "        \"out_dir\": str(out_dir),\n",
    "        \"tnr_thr05\": tnr,\n",
    "    }\n",
    "\n",
    "# =======================================================\n",
    "# MAIN\n",
    "# =======================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    results = []\n",
    "    for phase in PHASES:\n",
    "        try:\n",
    "            results.append(train_one_phase(phase))\n",
    "        except Exception as e:\n",
    "            print(f\"\\n[!] Skipped {phase} due to error: {e}\")\n",
    "\n",
    "    if results:\n",
    "        banner(\"GLOBAL SUMMARY ACROSS PHASES (HINT VALIDATION)\")\n",
    "        # Nice compact cross-phase table\n",
    "        header = (\n",
    "            \"Phase\", \"AUC(best chunk)\", \"BalAcc(best chunk)\", \n",
    "            \"AUC(calibrated, thr=0.5)\", \"BalAcc(calibrated, thr=0.5)\",\n",
    "            \"TNR(thr=0.5)\", \"Train shape\", \"Val shape\"\n",
    "        )\n",
    "        print(\"  \" + \" | \".join(f\"{h:^20}\" for h in header))\n",
    "        print(\"  \" + \"-\" * (len(header) * 23))\n",
    "        for r in results:\n",
    "            row = [\n",
    "                r[\"phase\"].replace(\"phase_\", \"Phase \"),\n",
    "                f\"{r['best_auc']:.4f}\",\n",
    "                f\"{r['best_bal_acc']:.4f}\",\n",
    "                f\"{r['val_auc_calibrated']:.4f}\",\n",
    "                f\"{r['val_balacc_calibrated']:.4f}\",\n",
    "                f\"{r['tnr_thr05']:.4f}\",\n",
    "                f\"{r['train_shape']}\",\n",
    "                f\"{r['val_shape']}\",\n",
    "            ]\n",
    "            print(\"  \" + \" | \".join(f\"{c:^20}\" for c in row))\n",
    "        print()\n",
    "        _print_tree(MODEL_BASE, \"All model package artifacts\")\n",
    "    else:\n",
    "        print(\"\\nNo phase was trained. Check errors above.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9979fdb3-5321-49b2-9595-c772d8eb7404",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (pytrial311)",
   "language": "python",
   "name": "pytrial311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
