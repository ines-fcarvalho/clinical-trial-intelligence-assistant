{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1uF5ecINJf54",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15190,
     "status": "ok",
     "timestamp": 1762516643097,
     "user": {
      "displayName": "Antonio Cortes",
      "userId": "07933854488654832685"
     },
     "user_tz": 0
    },
    "id": "1uF5ecINJf54",
    "outputId": "52d5704e-4fcf-42de-bce2-eb87708c318d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Building summary tables...\n",
      "==> Building figures...\n",
      "==> Building quick metric tables...\n",
      "==> Feature importance...\n",
      "==> Assembling HTML report...\n",
      "✔ Report HTML salvo em: /Users/antoniocortes/Tese/MyModel(hybrid)/report/performance_report.html\n",
      "\n",
      "✅ Done. Abra: report/performance_report.html\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# ============================================================\n",
    "# Unified Performance Report (HINT→CTOD & HINT→HINT)\n",
    "# - Gera TODAS as figuras e tabelas\n",
    "# - Exporta CSVs/PNGs e compila um HTML final (estático)\n",
    "# ============================================================\n",
    "\n",
    "from pathlib import Path\n",
    "import json, joblib, numpy as np, pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import sparse as sp\n",
    "import xgboost as xgb\n",
    "from string import Template\n",
    "import base64\n",
    "import re\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, average_precision_score, accuracy_score,\n",
    "    precision_recall_fscore_support, confusion_matrix,\n",
    "    roc_curve, precision_recall_curve\n",
    ")\n",
    "from sklearn.calibration import calibration_curve\n",
    "from sklearn.metrics import brier_score_loss\n",
    "\n",
    "# ---------------- CONFIG ----------------\n",
    "PHASES = [\"phase_I\", \"phase_II\", \"phase_III\"]\n",
    "\n",
    "# Ajuste estes caminhos para o seu ambiente:\n",
    "MODEL_BASE     = Path(\"/Users/antoniocortes/Tese/MyModel(hybrid)/xgb_model_package\")\n",
    "CTOD_ARTIFACTS = Path(\"/Users/antoniocortes/Tese/MyModel(hybrid)/ctod_xgb_artifacts\")\n",
    "HINT_ARTIFACTS = Path(\"/Users/antoniocortes/Tese/MyModel(hybrid)/hint_xgb_artifacts\")\n",
    "\n",
    "OUT_BASE   = Path(\"report\")              # pasta do relatório\n",
    "FIG_DIR    = OUT_BASE / \"fig\"\n",
    "TAB_DIR    = OUT_BASE / \"tables\"\n",
    "OUT_BASE.mkdir(parents=True, exist_ok=True)\n",
    "FIG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "TAB_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ---------------- HELPERS (dados/modelos) ----------------\n",
    "def _first_existing(*paths: Path) -> Path:\n",
    "    for p in paths:\n",
    "        if p.exists():\n",
    "            return p\n",
    "    raise FileNotFoundError(\"Artifact path not found:\\n\" + \"\\n\".join(map(str, paths)))\n",
    "\n",
    "def load_ctod_test(phase: str):\n",
    "    pdir = CTOD_ARTIFACTS / phase\n",
    "    X = sp.load_npz(pdir / \"X_test_joined_reduced.npz\")\n",
    "    y = np.load(pdir / \"y_test_joined.npy\")\n",
    "    return X, y\n",
    "\n",
    "def load_hint_test(phase: str):\n",
    "    base1 = HINT_ARTIFACTS / phase\n",
    "    base2 = HINT_ARTIFACTS / \"phases_reduced\" / phase\n",
    "    Xp = _first_existing(base1 / \"X_test_reduced.npz\", base2 / \"X_test_reduced.npz\")\n",
    "    yp = _first_existing(base1 / \"y_test.npy\",         base2 / \"y_test.npy\")\n",
    "    X = sp.load_npz(Xp); y = np.load(yp)\n",
    "    return X, y\n",
    "\n",
    "def load_hint_model(phase: str):\n",
    "    mdir = MODEL_BASE / phase\n",
    "    jl = mdir / \"hint_xgb_model.joblib\"\n",
    "    js = mdir / \"xgb_model.json\"\n",
    "    if jl.exists():\n",
    "        return joblib.load(jl)\n",
    "    booster = xgb.Booster(); booster.load_model(str(js))\n",
    "    mdl = xgb.XGBClassifier(); mdl._Booster = booster\n",
    "    return mdl\n",
    "\n",
    "# ---- Feature-name loader (tenta vários nomes de ficheiro) ----\n",
    "def _strip_leading_index(s: str) -> str:\n",
    "    s = s.strip()\n",
    "    m = re.match(r'^\\s*\\d+\\s*\"?(.+?)\"?\\s*$', s)\n",
    "    if m:\n",
    "        return m.group(1)\n",
    "    return s.strip('\"')\n",
    "\n",
    "def load_feature_names(phase: str):\n",
    "    base = MODEL_BASE / phase\n",
    "    candidates = [\n",
    "        base / \"feature_names_reduced_with_top_original\",\n",
    "        base / \"feature_names_reduced_with_top_original.json\",\n",
    "        base / \"feature_names_reduced.json\",\n",
    "        base / \"feature_names.json\",\n",
    "        base / \"feature_names.txt\",\n",
    "    ]\n",
    "    for path in candidates:\n",
    "        if path.exists():\n",
    "            # Tentar JSON\n",
    "            try:\n",
    "                with open(path) as f:\n",
    "                    data = json.load(f)\n",
    "                if isinstance(data, list) and all(isinstance(x, str) for x in data):\n",
    "                    return data\n",
    "            except Exception:\n",
    "                pass\n",
    "            # Tentar ficheiro linha-a-linha\n",
    "            try:\n",
    "                with open(path) as f:\n",
    "                    lines = [ln.strip() for ln in f if ln.strip()]\n",
    "                return [_strip_leading_index(ln) for ln in lines]\n",
    "            except Exception:\n",
    "                pass\n",
    "    print(f\"[WARN] Feature names file not found for {phase} (checked common candidates).\")\n",
    "    return None\n",
    "\n",
    "def map_f_to_name(fkey: str, feat_names):\n",
    "    if not (fkey and fkey.startswith(\"f\")) or feat_names is None:\n",
    "        return fkey\n",
    "    try:\n",
    "        idx = int(fkey[1:])\n",
    "        if 0 <= idx < len(feat_names):\n",
    "            return feat_names[idx]\n",
    "    except Exception:\n",
    "        pass\n",
    "    return fkey\n",
    "\n",
    "# ---------------- LIMPEZA DE NOMES (para plots de top features) ----------------\n",
    "SVD_TOKENS_RE = re.compile(r'^(svd(_component)?(_?\\d+)?)$', re.IGNORECASE)\n",
    "\n",
    "def _collapse_adjacent_dupes(parts):\n",
    "    out = []\n",
    "    for p in parts:\n",
    "        if not out or out[-1] != p:\n",
    "            out.append(p)\n",
    "    return out\n",
    "\n",
    "def _collapse_full_repeat(tokens):\n",
    "    n = len(tokens)\n",
    "    if n <= 1:\n",
    "        return tokens\n",
    "    for k in range(1, n // 2 + 1):\n",
    "        if n % k == 0 and tokens == tokens[:k] * (n // k):\n",
    "            return tokens[:k]\n",
    "    return tokens\n",
    "\n",
    "def clean_readable(name: str) -> str:\n",
    "    \"\"\"\n",
    "    Torna nomes técnicos mais legíveis e compactos:\n",
    "      - Remove repetições adjacentes e subsequências repetidas\n",
    "      - Converte '__' para ' · '\n",
    "      - Limpa _svd_*, 'd29' -> 'comp 29'\n",
    "      - Evita duplicar blocos (POS/SEM/ICD/...)\n",
    "    \"\"\"\n",
    "    s = str(name).strip().strip('\"')\n",
    "    parts = [p for p in s.split(\"__\") if p]\n",
    "    parts = _collapse_adjacent_dupes(parts)\n",
    "    parts = _collapse_full_repeat(parts)\n",
    "\n",
    "    # remover marcadores SVD e componentes dN\n",
    "    cleaned = []\n",
    "    for p in parts:\n",
    "        if SVD_TOKENS_RE.match(p):\n",
    "            continue\n",
    "        if re.fullmatch(r'[dD]\\d+', p):\n",
    "            continue\n",
    "        cleaned.append(p)\n",
    "    parts = cleaned\n",
    "\n",
    "    s = \"__\".join(parts)\n",
    "    # etiquetas “bonitas”\n",
    "    s = re.sub(r'^pos__', 'POS__', s)\n",
    "    s = re.sub(r'^sem__', 'SEM__', s)\n",
    "    s = s.replace(\"drugs_fusion__\", \"DRUGS__\")\n",
    "    s = s.replace(\"diseases_dual__\", \"DISEASES__\")\n",
    "    s = s.replace(\"icd__\", \"ICD__\")\n",
    "    s = s.replace(\"smiles__\", \"SMILES__\")\n",
    "    s = s.replace(\"brief_title__\", \"TITLE__\")\n",
    "    s = s.replace(\"description__\", \"DESC__\")\n",
    "\n",
    "    s = s.replace(\"__\", \" · \")\n",
    "    s = re.sub(r'\\s*_svd[_\\- ]?(\\d+)', r' · SVD \\1', s, flags=re.IGNORECASE)\n",
    "    s = re.sub(r'(?<![A-Za-z0-9])d(\\d+)(?![A-Za-z0-9])', r'comp \\1', s)\n",
    "\n",
    "    # dedup tokens finais e subsequências\n",
    "    tokens = [t.strip() for t in s.split(\"·\")]\n",
    "    tokens = [t for t in tokens if t]\n",
    "    tokens = _collapse_adjacent_dupes(tokens)\n",
    "    tokens = _collapse_full_repeat(tokens)\n",
    "\n",
    "    BLOCK_TAGS = {\"POS\", \"SEM\", \"ICD\", \"DRUGS\", \"DISEASES\", \"SMILES\", \"TITLE\", \"DESC\", \"SVD\"}\n",
    "    pretty = []\n",
    "    for t in tokens:\n",
    "        tt = re.sub(r'\\s{2,}', ' ', t.strip())\n",
    "        if 1 <= len(tt) <= 3 and tt.isalpha() and tt.upper() not in BLOCK_TAGS and tt.islower():\n",
    "            tt = f'\"{tt}\"'\n",
    "        pretty.append(tt)\n",
    "    out = \" · \".join(pretty)\n",
    "    return re.sub(r'\\s{2,}', ' ', out).strip()\n",
    "\n",
    "# ---------------- METRICS UTILS ----------------\n",
    "def metrics_at_threshold(y_true, proba, thr=0.5):\n",
    "    pred = (proba >= thr).astype(int)\n",
    "    acc  = accuracy_score(y_true, pred)\n",
    "    prec, rec, f1, _ = precision_recall_fscore_support(y_true, pred, average=\"binary\", zero_division=0)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, pred).ravel()\n",
    "    tnr = tn / (tn + fp + 1e-9)\n",
    "    bal = 0.5 * (tnr + rec)\n",
    "    return dict(threshold=float(thr), accuracy=float(acc), precision=float(prec), recall=float(rec),\n",
    "                f1=float(f1), tnr=float(tnr), bal_acc=float(bal),\n",
    "                cm=dict(tn=int(tn), fp=int(fp), fn=int(fn), tp=int(tp)))\n",
    "\n",
    "def pick_threshold_balacc_max(y_true, proba):\n",
    "    fpr, tpr, thr = roc_curve(y_true, proba)\n",
    "    candidates = np.unique(np.r_[thr, 0.5])\n",
    "    def balacc_at(t):\n",
    "        pred=(proba>=t).astype(int)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_true, pred).ravel()\n",
    "        tnr = tn/(tn+fp+1e-9); tpr_=tp/(tp+fn+1e-9)\n",
    "        return 0.5*(tnr+tpr_)\n",
    "    scores = np.array([balacc_at(t) for t in candidates])\n",
    "    i = int(np.argmax(scores))\n",
    "    return float(candidates[i]), float(scores[i])\n",
    "\n",
    "def best_f1_from_pr(y_true, proba):\n",
    "    prec, rec, ths = precision_recall_curve(y_true, proba)\n",
    "    f1s = 2 * prec * rec / (prec + rec + 1e-9)\n",
    "    core = f1s[:-1]\n",
    "    if core.size == 0: return float(\"nan\")\n",
    "    mx = np.nanmax(core)\n",
    "    return float(mx) if np.isfinite(mx) else float(\"nan\")\n",
    "\n",
    "# ---------------- FIGURE HELPERS ----------------\n",
    "def _savefig(fig, path: Path):\n",
    "    fig.savefig(path, dpi=150, bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n",
    "\n",
    "# ---------------- BUILDERS ----------------\n",
    "def build_summary_tables():\n",
    "    # PR/AP, F1 best, ROC — para CTOD e HINT\n",
    "    rows_ctod, rows_hint = [], []\n",
    "    for phase in PHASES:\n",
    "        mdl = load_hint_model(phase)\n",
    "\n",
    "        Xc, yc = load_ctod_test(phase)\n",
    "        pc = mdl.predict_proba(Xc)[:, 1]\n",
    "        rows_ctod.append({\"Phase\": phase,\n",
    "                          \"PR (AP)\": average_precision_score(yc, pc),\n",
    "                          \"F1 (Best)\": best_f1_from_pr(yc, pc),\n",
    "                          \"ROC AUC\": roc_auc_score(yc, pc)})\n",
    "\n",
    "        Xh, yh = load_hint_test(phase)\n",
    "        ph = mdl.predict_proba(Xh)[:, 1]\n",
    "        rows_hint.append({\"Phase\": phase,\n",
    "                          \"PR (AP)\": average_precision_score(yh, ph),\n",
    "                          \"F1 (Best)\": best_f1_from_pr(yh, ph),\n",
    "                          \"ROC AUC\": roc_auc_score(yh, ph)})\n",
    "\n",
    "    df_ctod = pd.DataFrame(rows_ctod).set_index(\"Phase\")\n",
    "    df_hint = pd.DataFrame(rows_hint).set_index(\"Phase\")\n",
    "    combined = pd.concat({\"CTOD\": df_ctod, \"HINT\": df_hint}, axis=1)\n",
    "\n",
    "    df_ctod.to_csv(TAB_DIR / \"summary_ctod.csv\")\n",
    "    df_hint.to_csv(TAB_DIR / \"summary_hint.csv\")\n",
    "    combined.to_csv(TAB_DIR / \"summary_combined.csv\")\n",
    "    return df_ctod, df_hint, combined\n",
    "\n",
    "def build_confusion_grid(thr=0.5):\n",
    "    nrows, ncols = len(PHASES), 2\n",
    "    fig, axes = plt.subplots(nrows, ncols, figsize=(11, 4.8 * nrows), sharex=True, sharey=True,\n",
    "                             gridspec_kw={\"wspace\": -0.3, \"hspace\": 0.9})\n",
    "\n",
    "    def _plot_cm(ax, y_true, proba, title):\n",
    "        y_pred = (proba >= thr).astype(int)\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        tn, fp, fn, tp = cm.ravel()\n",
    "        tpr = tp / (tp + fn + 1e-9)\n",
    "        tnr = tn / (tn + fp + 1e-9)\n",
    "        prec = tp / (tp + fp + 1e-9)\n",
    "        acc = accuracy_score(y_true, y_pred)\n",
    "        bal = 0.5 * (tpr + tnr)\n",
    "\n",
    "        ax.imshow(cm, cmap=plt.cm.Blues, alpha=0.6, interpolation=\"nearest\")\n",
    "        ax.set_title(title, fontsize=12, fontweight=\"bold\", pad=8)\n",
    "        ax.set_xlabel(\"Predicted\"); ax.set_xticks([0,1]); ax.set_xticklabels([\"0 (neg)\",\"1 (pos)\"])\n",
    "        ax.set_yticks([0,1]); ax.set_yticklabels([\"0 (neg)\",\"1 (pos)\"])\n",
    "        labels = np.array([[\"TN\",\"FP\"],[\"FN\",\"TP\"]])\n",
    "        for (r,c), val in np.ndenumerate(cm):\n",
    "            ax.text(c, r, f\"{labels[r,c]}\\n{val:,}\", ha=\"center\", va=\"center\", fontsize=11, fontweight=\"bold\")\n",
    "\n",
    "        ax.text(1.03, 0.5,\n",
    "                f\"Acc={acc:.3f}\\nPrec={prec:.3f}\\nRec={tpr:.3f}\\nTNR={tnr:.3f}\\nBal={bal:.3f}\",\n",
    "                ha=\"left\", va=\"center\", fontsize=10, transform=ax.transAxes,\n",
    "                bbox=dict(boxstyle=\"round,pad=0.25\", facecolor=\"white\", alpha=0.85, linewidth=0))\n",
    "\n",
    "        for s in ax.spines.values(): s.set_visible(False)\n",
    "        ax.set_xticks(np.arange(-0.5, 2, 1), minor=True)\n",
    "        ax.set_yticks(np.arange(-0.5, 2, 1), minor=True)\n",
    "        ax.grid(which=\"minor\", color=\"white\", linestyle=\"-\", linewidth=2)\n",
    "\n",
    "    for i, phase in enumerate(PHASES):\n",
    "        mdl = load_hint_model(phase)\n",
    "\n",
    "        Xc, yc = load_ctod_test(phase); pc = mdl.predict_proba(Xc)[:,1]\n",
    "        _plot_cm(axes[i,0], yc, pc, f\"{phase.upper()} — CTOD\")\n",
    "\n",
    "        Xh, yh = load_hint_test(phase); ph = mdl.predict_proba(Xh)[:,1]\n",
    "        _plot_cm(axes[i,1], yh, ph, f\"{phase.upper()} — HINT\")\n",
    "\n",
    "        axes[i,0].text(-0.8, 1.0, phase.upper(), va=\"bottom\", ha=\"center\",\n",
    "                       rotation=90, fontsize=12, fontweight=\"bold\", transform=axes[i,0].transAxes)\n",
    "\n",
    "    axes[0,0].set_title(\"CTOD (HINT → CTOD)\", fontsize=13, fontweight=\"bold\")\n",
    "    axes[0,1].set_title(\"HINT (HINT → HINT)\", fontsize=13, fontweight=\"bold\")\n",
    "    fig.suptitle(\"Confusion Matrices by Phase and Dataset\", fontsize=15, fontweight=\"bold\", y=0.98)\n",
    "    _savefig(fig, FIG_DIR / \"confusion_grid.png\")\n",
    "\n",
    "def build_roc_grid():\n",
    "    fig, axes = plt.subplots(len(PHASES), 2, figsize=(12, 12), sharex=True, sharey=True)\n",
    "    for i, phase in enumerate(PHASES):\n",
    "        mdl = load_hint_model(phase)\n",
    "\n",
    "        # CTOD\n",
    "        ax = axes[i,0]; Xc,yc = load_ctod_test(phase); pc = mdl.predict_proba(Xc)[:,1]\n",
    "        fpr, tpr, _ = roc_curve(yc, pc); auc = roc_auc_score(yc, pc)\n",
    "        ax.plot(fpr, tpr, label=f\"AUC = {auc:.3f}\", linewidth=2, color=\"#ff7f0e\")\n",
    "        ax.plot([0,1],[0,1],'--', color=\"gray\", linewidth=1); ax.grid(True, linestyle=\":\", linewidth=0.5)\n",
    "        if i == len(PHASES)-1: ax.set_xlabel(\"False Positive Rate\")\n",
    "        ax.set_ylabel(f\"{phase}\\nTrue Positive Rate (Recall)\")\n",
    "        ax.legend(loc=\"lower right\", fontsize=9)\n",
    "\n",
    "        # HINT\n",
    "        ax = axes[i,1]; Xh,yh = load_hint_test(phase); ph = mdl.predict_proba(Xh)[:,1]\n",
    "        fpr, tpr, _ = roc_curve(yh, ph); auc = roc_auc_score(yh, ph)\n",
    "        ax.plot(fpr, tpr, label=f\"AUC = {auc:.3f}\", linewidth=2, color=\"#1f77b4\")\n",
    "        ax.plot([0,1],[0,1],'--', color=\"gray\", linewidth=1); ax.grid(True, linestyle=\":\", linewidth=0.5)\n",
    "        if i == len(PHASES)-1: ax.set_xlabel(\"False Positive Rate\")\n",
    "        ax.legend(loc=\"lower right\", fontsize=9)\n",
    "\n",
    "    axes[0,0].set_title(\"HINT → CTOD\", fontsize=13, fontweight=\"bold\")\n",
    "    axes[0,1].set_title(\"HINT → HINT\", fontsize=13, fontweight=\"bold\")\n",
    "    fig.suptitle(\"ROC Curves by Phase and Dataset\", fontsize=15, fontweight=\"bold\", y=1.02)\n",
    "    _savefig(fig, FIG_DIR / \"roc_grid.png\")\n",
    "\n",
    "def build_pr_grid():\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 10), sharex=True, sharey=True)\n",
    "\n",
    "    # Row 1: CTOD\n",
    "    for i, phase in enumerate(PHASES):\n",
    "        ax = axes[0,i]\n",
    "        mdl = load_hint_model(phase); Xc,yc = load_ctod_test(phase); pc = mdl.predict_proba(Xc)[:,1]\n",
    "        prec, rec, _ = precision_recall_curve(yc, pc); ap = average_precision_score(yc, pc)\n",
    "        ax.plot(rec, prec, label=f\"AP = {ap:.3f}\", linewidth=2)\n",
    "        ax.set_title(f\"{phase.upper()}\", fontsize=12); ax.legend(loc=\"lower left\", fontsize=9); ax.grid(True, linestyle=\":\", linewidth=0.5)\n",
    "        if i == 0:\n",
    "            ax.set_ylabel(\"Precision\")\n",
    "            ax.text(-0.3, 0.5, \"CTOD\", va=\"center\", ha=\"center\", rotation=90, fontsize=12, fontweight=\"bold\", transform=ax.transAxes)\n",
    "\n",
    "    # Row 2: HINT\n",
    "    for i, phase in enumerate(PHASES):\n",
    "        ax = axes[1,i]\n",
    "        mdl = load_hint_model(phase); Xh,yh = load_hint_test(phase); ph = mdl.predict_proba(Xh)[:,1]\n",
    "        prec, rec, _ = precision_recall_curve(yh, ph); ap = average_precision_score(yh, ph)\n",
    "        ax.plot(rec, prec, label=f\"AP = {ap:.3f}\", linewidth=2, color=\"#1f77b4\")\n",
    "        ax.set_xlabel(\"Recall\"); ax.legend(loc=\"lower left\", fontsize=9); ax.grid(True, linestyle=\":\", linewidth=0.5)\n",
    "        if i == 0:\n",
    "            ax.set_ylabel(\"Precision\")\n",
    "            ax.text(-0.3, 0.5, \"HINT\", va=\"center\", ha=\"center\", rotation=90, fontsize=12, fontweight=\"bold\", transform=ax.transAxes)\n",
    "\n",
    "    fig.suptitle(\"Precision–Recall — HINT→CTOD (top) & HINT→HINT (bottom)\", fontsize=14, fontweight=\"bold\", y=1.02)\n",
    "    _savefig(fig, FIG_DIR / \"pr_grid.png\")\n",
    "\n",
    "def build_calibration_grid():\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 10), sharex=True, sharey=True)\n",
    "\n",
    "    # Row 1: CTOD\n",
    "    for i, phase in enumerate(PHASES):\n",
    "        ax = axes[0,i]\n",
    "        mdl = load_hint_model(phase); Xc,yc = load_ctod_test(phase); pc = mdl.predict_proba(Xc)[:,1]\n",
    "        brier = brier_score_loss(yc, pc)\n",
    "        prob_true, prob_pred = calibration_curve(yc, pc, n_bins=10, strategy=\"quantile\")\n",
    "        ax.plot(prob_pred, prob_true, marker='o', linewidth=2, label=f\"Brier = {brier:.3f}\")\n",
    "        ax.plot([0,1],[0,1],'--', linewidth=1, color=\"gray\"); ax.set_title(f\"{phase.upper()}\", fontsize=12)\n",
    "        ax.legend(loc=\"upper left\", fontsize=9); ax.grid(True, linestyle=\":\", linewidth=0.5)\n",
    "        if i == 0:\n",
    "            ax.set_ylabel(\"Observed frequency\")\n",
    "            ax.text(-0.3, 0.5, \"CTOD\", va=\"center\", ha=\"center\", rotation=90, fontsize=12, fontweight=\"bold\", transform=ax.transAxes)\n",
    "\n",
    "    # Row 2: HINT\n",
    "    for i, phase in enumerate(PHASES):\n",
    "        ax = axes[1,i]\n",
    "        mdl = load_hint_model(phase); Xh,yh = load_hint_test(phase); ph = mdl.predict_proba(Xh)[:,1]\n",
    "        brier = brier_score_loss(yh, ph)\n",
    "        prob_true, prob_pred = calibration_curve(yh, ph, n_bins=10, strategy=\"quantile\")\n",
    "        ax.plot(prob_pred, prob_true, marker='o', linewidth=2, label=f\"Brier = {brier:.3f}\", color=\"#1f77b4\")\n",
    "        ax.plot([0,1],[0,1],'--', linewidth=1, color=\"gray\"); ax.set_xlabel(\"Predicted probability\")\n",
    "        ax.legend(loc=\"upper left\", fontsize=9); ax.grid(True, linestyle=\":\", linewidth=0.5)\n",
    "        if i == 0:\n",
    "            ax.set_ylabel(\"Observed frequency\")\n",
    "            ax.text(-0.3, 0.5, \"HINT\", va=\"center\", ha=\"center\", rotation=90, fontsize=12, fontweight=\"bold\", transform=ax.transAxes)\n",
    "\n",
    "    fig.suptitle(\"Calibration — HINT→CTOD (top) & HINT→HINT (bottom)\", fontsize=14, fontweight=\"bold\", y=1.02)\n",
    "    _savefig(fig, FIG_DIR / \"calibration_grid.png\")\n",
    "\n",
    "def build_threshold_sweep_grid():\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 10), sharex=True, sharey=True)\n",
    "\n",
    "    # Row 1: CTOD\n",
    "    for i, phase in enumerate(PHASES):\n",
    "        ax = axes[0,i]\n",
    "        mdl = load_hint_model(phase); Xc,yc = load_ctod_test(phase); pc = mdl.predict_proba(Xc)[:,1]\n",
    "        ths = np.linspace(0.01, 0.99, 99)\n",
    "        bal, tnr_list, tpr_list = [], [], []\n",
    "        for t in ths:\n",
    "            pred = (pc >= t).astype(int)\n",
    "            tn, fp, fn, tp = confusion_matrix(yc, pred).ravel()\n",
    "            tnr = tn / (tn + fp + 1e-9); tpr = tp / (tp + fn + 1e-9)\n",
    "            tnr_list.append(tnr); tpr_list.append(tpr); bal.append(0.5*(tnr+tpr))\n",
    "        t_bal = float(ths[np.argmax(bal)])\n",
    "        ax.plot(ths, bal, label=\"Balanced Acc\", linewidth=2)\n",
    "        ax.plot(ths, tnr_list, linestyle=\"--\", label=\"TNR (Spec.)\")\n",
    "        ax.plot(ths, tpr_list, linestyle=\"--\", label=\"TPR (Recall)\")\n",
    "        ax.axvline(t_bal, linestyle=\":\", color=\"black\", label=f\"BalAcc-max @ {t_bal:.3f}\")\n",
    "        ax.set_title(f\"{phase.upper()}\"); ax.legend(fontsize=8); ax.grid(True, linestyle=\":\", linewidth=0.5)\n",
    "        if i == 0:\n",
    "            ax.set_ylabel(\"Score\")\n",
    "            ax.text(-0.25, 0.5, \"CTOD\", va=\"center\", ha=\"center\", rotation=90, fontsize=12, fontweight=\"bold\", transform=ax.transAxes)\n",
    "\n",
    "    # Row 2: HINT\n",
    "    for i, phase in enumerate(PHASES):\n",
    "        ax = axes[1,i]\n",
    "        mdl = load_hint_model(phase); Xh,yh = load_hint_test(phase); ph = mdl.predict_proba(Xh)[:,1]\n",
    "        ths = np.linspace(0.01, 0.99, 99)\n",
    "        bal, tnr_list, tpr_list = [], [], []\n",
    "        for t in ths:\n",
    "            pred = (ph >= t).astype(int)\n",
    "            tn, fp, fn, tp = confusion_matrix(yh, pred).ravel()\n",
    "            tnr = tn / (tn + fp + 1e-9); tpr = tp / (tp + fn + 1e-9)\n",
    "            tnr_list.append(tnr); tpr_list.append(tpr); bal.append(0.5*(tnr+tpr))\n",
    "        t_bal = float(ths[np.argmax(bal)])\n",
    "        ax.plot(ths, bal, label=\"Balanced Acc\", linewidth=2, color=\"#1f77b4\")\n",
    "        ax.plot(ths, tnr_list, linestyle=\"--\", label=\"TNR (Spec.)\")\n",
    "        ax.plot(ths, tpr_list, linestyle=\"--\", label=\"TPR (Recall)\")\n",
    "        ax.axvline(t_bal, linestyle=\":\", color=\"black\", label=f\"BalAcc-max @ {t_bal:.3f}\")\n",
    "        ax.set_xlabel(\"Threshold\")\n",
    "        if i == 0:\n",
    "            ax.set_ylabel(\"Score\")\n",
    "            ax.text(-0.25, 0.5, \"HINT\", va=\"center\", ha=\"center\", rotation=90, fontsize=12, fontweight=\"bold\", transform=ax.transAxes)\n",
    "\n",
    "    fig.suptitle(\"Threshold Sweep — HINT→CTOD (top) & HINT→HINT (bottom)\", fontsize=14, fontweight=\"bold\", y=1.02)\n",
    "    _savefig(fig, FIG_DIR / \"threshold_sweep_grid.png\")\n",
    "\n",
    "def feature_importance_plots():\n",
    "    # Top features por ganho (normalizado) com nomes legíveis\n",
    "    for phase in PHASES:\n",
    "        mdl = load_hint_model(phase); booster = mdl.get_booster()\n",
    "        feat_names = load_feature_names(phase)\n",
    "\n",
    "        gain_scores   = booster.get_score(importance_type=\"gain\")\n",
    "        cover_scores  = booster.get_score(importance_type=\"cover\")\n",
    "        weight_scores = booster.get_score(importance_type=\"weight\")\n",
    "        if not gain_scores:\n",
    "            print(f\"[{phase}] No importance available.\"); continue\n",
    "\n",
    "        # usar união de chaves (evita perder features que só têm cover/weight)\n",
    "        all_keys = set(gain_scores) | set(cover_scores) | set(weight_scores)\n",
    "        df = pd.DataFrame({\"Feature\": list(all_keys)})\n",
    "        df[\"Gain\"]   = df[\"Feature\"].map(lambda f: gain_scores.get(f, 0.0))\n",
    "        df[\"Cover\"]  = df[\"Feature\"].map(lambda f: cover_scores.get(f, 0.0))\n",
    "        df[\"Weight\"] = df[\"Feature\"].map(lambda f: weight_scores.get(f, 0.0))\n",
    "\n",
    "        # mapear para nome legível e limpar\n",
    "        df[\"ReadableFeature_raw\"] = df[\"Feature\"].map(lambda f: map_f_to_name(f, feat_names))\n",
    "        df[\"ReadableFeature\"]     = df[\"ReadableFeature_raw\"].map(clean_readable)\n",
    "\n",
    "        total_gain = df[\"Gain\"].sum()\n",
    "        df[\"Gain_norm\"] = df[\"Gain\"] / total_gain if total_gain > 0 else 0.0\n",
    "        df = df.sort_values(\"Gain\", ascending=False).reset_index(drop=True)\n",
    "        df.to_csv(TAB_DIR / f\"feature_importance_{phase}.csv\", index=False)\n",
    "\n",
    "        top = df.head(15)\n",
    "        fig = plt.figure(figsize=(9, 6))\n",
    "        plt.barh(range(len(top)), top[\"Gain_norm\"][::-1])\n",
    "        plt.yticks(range(len(top)), top[\"ReadableFeature\"][::-1], fontsize=9)\n",
    "        plt.xlabel(\"Normalized Gain\"); plt.title(f\"Feature Importance — {phase.upper()}\")\n",
    "        plt.grid(True, axis=\"x\", linestyle=\":\", linewidth=0.5)\n",
    "        _savefig(fig, FIG_DIR / f\"feature_importance_{phase}.png\")\n",
    "\n",
    "# --------- Agregação por COLUNA ORIGINAL (com renames pedidos) ---------\n",
    "HEAD_WIDTH = {\n",
    "    \"pos\": 2,\n",
    "    \"sem\": 2,\n",
    "    \"diseases_dual\": 1,\n",
    "    \"drugs_fusion\": 1,\n",
    "    \"icd\": 1,\n",
    "    \"smiles\": 1,\n",
    "    \"brief_title\": 1,\n",
    "    \"description\": 1,\n",
    "    \"title\": 1,\n",
    "    \"desc\": 1,\n",
    "    \"num\": 1,  # ex.: num__enrollment\n",
    "}\n",
    "\n",
    "def extract_origin_column(raw_name: str) -> str:\n",
    "    \"\"\"\n",
    "    A partir do nome guardado (após SVD), extrai a 'coluna origem' e aplica renames:\n",
    "      - sem__criteria* -> llm__criteria\n",
    "      - sem__smiles*   -> llm__smiles\n",
    "      - num*           -> enrollment\n",
    "    \"\"\"\n",
    "    s = _strip_leading_index(str(raw_name)).strip().strip('\"')\n",
    "    parts = [p for p in s.split(\"__\") if p]\n",
    "    parts = _collapse_adjacent_dupes(parts)\n",
    "    parts = _collapse_full_repeat(parts)\n",
    "\n",
    "    # remove marcadores de SVD e componentes dN\n",
    "    cleaned = []\n",
    "    for p in parts:\n",
    "        if SVD_TOKENS_RE.match(p):\n",
    "            continue\n",
    "        if re.fullmatch(r'[dD]\\d+', p):\n",
    "            continue\n",
    "        cleaned.append(p)\n",
    "    parts = cleaned\n",
    "\n",
    "    if not parts:\n",
    "        return str(raw_name)\n",
    "\n",
    "    head = parts[0].lower()\n",
    "    if head in HEAD_WIDTH:\n",
    "        take = min(HEAD_WIDTH[head], len(parts))\n",
    "        origin = \"__\".join(parts[:take])\n",
    "    else:\n",
    "        origin = parts[0]\n",
    "\n",
    "    # Renomeações para visualização/CSV\n",
    "    if origin.startswith(\"sem__criteria\"):\n",
    "        origin = \"llm__criteria\"\n",
    "    elif origin.startswith(\"sem__smiles\"):\n",
    "        origin = \"llm__smiles\"\n",
    "    elif origin.startswith(\"num\"):\n",
    "        origin = \"enrollment\"\n",
    "\n",
    "    return origin\n",
    "\n",
    "def feature_importance_by_column():\n",
    "    for phase in PHASES:\n",
    "        mdl = load_hint_model(phase); booster = mdl.get_booster()\n",
    "        feat_names = load_feature_names(phase)\n",
    "        imp_gain = booster.get_score(importance_type=\"gain\")\n",
    "        cover    = booster.get_score(importance_type=\"cover\")\n",
    "        weight   = booster.get_score(importance_type=\"weight\")\n",
    "\n",
    "        all_keys = set(imp_gain) | set(cover) | set(weight)\n",
    "        rows = []\n",
    "        for fkey in all_keys:\n",
    "            idx = int(fkey[1:]) if fkey.startswith(\"f\") else None\n",
    "            readable = feat_names[idx] if (idx is not None and feat_names and idx < len(feat_names)) else fkey\n",
    "            col = extract_origin_column(readable)\n",
    "            rows.append({\n",
    "                \"BoosterKey\": fkey,\n",
    "                \"Feature\": readable,\n",
    "                \"OriginColumn\": col,\n",
    "                \"Gain\": float(imp_gain.get(fkey, 0.0)),\n",
    "                \"Cover\": float(cover.get(fkey, 0.0)),\n",
    "                \"Weight\": float(weight.get(fkey, 0.0)),\n",
    "            })\n",
    "        df_feat = pd.DataFrame(rows)\n",
    "        if df_feat.empty:\n",
    "            print(f\"[{phase}] No importance by column.\"); \n",
    "            continue\n",
    "\n",
    "        agg = (df_feat.groupby(\"OriginColumn\", as_index=False)\n",
    "               .agg(Gain=(\"Gain\",\"sum\"), Cover=(\"Cover\",\"sum\"), Weight=(\"Weight\",\"sum\"), Features=(\"BoosterKey\",\"count\"))\n",
    "               .sort_values(\"Gain\", ascending=False).reset_index(drop=True))\n",
    "        total_gain = agg[\"Gain\"].sum()\n",
    "        agg[\"Gain_norm\"] = agg[\"Gain\"] / total_gain if total_gain > 0 else 0.0\n",
    "        agg[\"Gain_pct\"]  = agg[\"Gain_norm\"] * 100.0\n",
    "\n",
    "        agg.to_csv(TAB_DIR / f\"feature_importance_by_column_{phase}.csv\", index=False)\n",
    "\n",
    "        top = agg.head(20)\n",
    "        fig = plt.figure(figsize=(8, 0.35*len(top) + 2))\n",
    "        plt.barh(range(len(top)), top[\"Gain_norm\"][::-1])\n",
    "        plt.yticks(range(len(top)), top[\"OriginColumn\"][::-1], fontsize=10)\n",
    "        plt.xlabel(\"Normalized importance (gain)\")\n",
    "        plt.title(f\"Feature importance by ORIGINAL COLUMN — {phase.upper()}\")\n",
    "        plt.grid(True, axis=\"x\", linestyle=\":\", linewidth=0.5)\n",
    "        _savefig(fig, FIG_DIR / f\"feature_importance_by_column_{phase}.png\")\n",
    "\n",
    "# ---------------- HTML ----------------\n",
    "def build_html_report(df_ctod, df_hint, df_combined, quick_tables_files):\n",
    "    def _tbl(df: pd.DataFrame, title: str) -> str:\n",
    "        try:\n",
    "            df_disp = df.copy()\n",
    "            # arredondar apenas colunas numéricas\n",
    "            num_cols = df_disp.select_dtypes(include=[np.number]).columns\n",
    "            df_disp[num_cols] = df_disp[num_cols].round(4)\n",
    "            return f\"<h3>{title}</h3>\\n\" + df_disp.to_html(classes='table', border=0)\n",
    "        except Exception as e:\n",
    "            return f\"<h3>{title}</h3>\\n<div class='caption' style='color:#b00'>[table render error: {e}]</div>\"\n",
    "\n",
    "    def inline_img(png_path: Path) -> str:\n",
    "        if not png_path.exists():\n",
    "            return f\"<div class='caption' style='color:#b00'>[missing image: {png_path.name}]</div>\"\n",
    "        b64 = base64.b64encode(png_path.read_bytes()).decode(\"ascii\")\n",
    "        return f\"<img src='data:image/png;base64,{b64}' style='max-width:100%'/>\"\n",
    "\n",
    "    phases_str = \", \".join(PHASES)\n",
    "\n",
    "    head_tpl = Template(r\"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html lang=\"en\"><head>\n",
    "<meta charset=\"utf-8\"/>\n",
    "<title>Performance Evaluation Report</title>\n",
    "<style>\n",
    "body{font-family:system-ui,-apple-system,Segoe UI,Roboto,Ubuntu,Arial,sans-serif; margin:24px; line-height:1.45}\n",
    "h1,h2,h3{margin-top:1.2em}\n",
    ".figure{border:1px solid #eee; padding:12px; border-radius:8px; background:#fafafa}\n",
    ".caption{font-size:0.9em; color:#555; margin-top:6px}\n",
    ".table{border-collapse:collapse}\n",
    ".table th,.table td{padding:6px 10px; border-bottom:1px solid #eee; text-align:right}\n",
    ".table th:first-child,.table td:first-child{text-align:left}\n",
    "</style>\n",
    "</head><body>\n",
    "<h1>Performance Evaluation Report</h1>\n",
    "<p><b>Pipelines:</b> HINT→CTOD e HINT→HINT | Fases: ${phases}</p>\n",
    "\"\"\")\n",
    "\n",
    "    html = []\n",
    "    html.append(head_tpl.substitute(phases=phases_str))\n",
    "\n",
    "    # 1) Sumários\n",
    "    html.append(\"<h2>1) Summary Metrics</h2>\")\n",
    "    html.append(_tbl(df_combined, \"CTOD vs HINT (AP, F1-best, ROC AUC)\"))\n",
    "\n",
    "    # 2) Tabelas por fase\n",
    "    html.append(\"<h2>2) Threshold (0.5 vs Tuned)</h2>\")\n",
    "    for phase in PHASES:\n",
    "        csv_path = quick_tables_files.get(phase)\n",
    "        if not csv_path or not Path(csv_path).exists():\n",
    "            html.append(f\"<div class='caption' style='color:#b00'>[missing table: quick_metrics_{phase}.csv]</div>\")\n",
    "            continue\n",
    "        try:\n",
    "            df = pd.read_csv(csv_path, header=0, index_col=0)\n",
    "        except Exception as e:\n",
    "            html.append(f\"<div class='caption' style='color:#b00'>[error reading {csv_path}: {e}]</div>\")\n",
    "            continue\n",
    "        html.append(_tbl(df, f\"Phase {phase.upper()} — CTOD & HINT\"))\n",
    "\n",
    "    # helper para secções com figura + legenda\n",
    "    def fig_card(png_name: str, caption: str) -> str:\n",
    "        return f\"\"\"\n",
    "<div class=\"figure\">\n",
    "  {inline_img(FIG_DIR / png_name)}\n",
    "  <div class=\"caption\">{caption}</div>\n",
    "</div>\n",
    "\"\"\"\n",
    "\n",
    "    # 3) ROC / PR\n",
    "    html.append(\"<h2>3) ROC / PR</h2>\")\n",
    "    html.append(fig_card(\"roc_grid.png\", \"ROC curves by phase (esq: CTOD, dir: HINT)\"))\n",
    "    html.append(fig_card(\"pr_grid.png\", \"Precision–Recall — topo: CTOD, baixo: HINT\"))\n",
    "\n",
    "    # 4) Confusion & Calibration\n",
    "    html.append(\"<h2>4) Confusion & Calibration</h2>\")\n",
    "    html.append(fig_card(\"confusion_grid.png\", \"Confusion matrices (thr=0.5)\"))\n",
    "    html.append(fig_card(\"calibration_grid.png\", \"Calibration curves (Brier score em legenda)\"))\n",
    "\n",
    "    # 5) Threshold Sweep\n",
    "    html.append(\"<h2>5) Threshold Sweep</h2>\")\n",
    "    html.append(fig_card(\"threshold_sweep_grid.png\", \"BalancedAcc / TNR / TPR vs threshold\"))\n",
    "\n",
    "    # 6) Feature Importance\n",
    "    html.append(\"<h2>6) Feature Importance</h2>\")\n",
    "    for phase in PHASES:\n",
    "        html.append(fig_card(f\"feature_importance_{phase}.png\", f\"Top features — {phase.upper()} (gain normalizado)\"))\n",
    "        html.append(fig_card(f\"feature_importance_by_column_{phase}.png\", f\"Por coluna original — {phase.upper()}\"))\n",
    "\n",
    "    html.append(\"\"\"\n",
    "<hr/>\n",
    "<p><small>Gerado automaticamente por unified_performance_report.py</small></p>\n",
    "</body></html>\"\"\")\n",
    "\n",
    "    (OUT_BASE / \"performance_report.html\").write_text(\"\\n\".join(html), encoding=\"utf-8\")\n",
    "    print(f\"✔ Report HTML salvo em: {(OUT_BASE / 'performance_report.html').resolve()}\")\n",
    "\n",
    "# ---------------- MAIN ----------------\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"==> Building summary tables...\")\n",
    "    df_ctod, df_hint, df_combined = build_summary_tables()\n",
    "\n",
    "    print(\"==> Building figures...\")\n",
    "    build_roc_grid()\n",
    "    build_pr_grid()\n",
    "    build_confusion_grid(thr=0.5)\n",
    "    build_calibration_grid()\n",
    "    build_threshold_sweep_grid()\n",
    "\n",
    "    print(\"==> Building quick metric tables...\")\n",
    "    qtbl_files = {}\n",
    "    qtbl = {}\n",
    "    # Guardar as tabelas por fase como CSV e devolver paths\n",
    "    def quick_metric_tables():\n",
    "        def summary_table_from(m_default, m_tuned, tuned_thr):\n",
    "            def row_from(m):\n",
    "                return {\"Threshold\": m[\"threshold\"], \"Accuracy\": m[\"accuracy\"], \"Precision\": m[\"precision\"],\n",
    "                        \"Recall (TPR)\": m[\"recall\"], \"Specificity (TNR)\": m[\"tnr\"],\n",
    "                        \"BalancedAcc\": m[\"bal_acc\"], \"F1\": m[\"f1\"],\n",
    "                        \"TP\": m[\"cm\"][\"tp\"], \"FP\": m[\"cm\"][\"fp\"], \"FN\": m[\"cm\"][\"fn\"], \"TN\": m[\"cm\"][\"tn\"]}\n",
    "            df = pd.DataFrame([row_from(m_default), row_from(m_tuned)],\n",
    "                              index=[\"Default (0.5)\", f\"Tuned (BalAcc max @ {tuned_thr:.3f})\"])\n",
    "            delta = (df.iloc[1] - df.iloc[0]).to_frame().T\n",
    "            delta.index = [\"Δ (tuned − default)\"]\n",
    "            df = pd.concat([df, delta], axis=0)\n",
    "            return df\n",
    "\n",
    "        out = {}\n",
    "        for phase in PHASES:\n",
    "            mdl = load_hint_model(phase)\n",
    "\n",
    "            # CTOD\n",
    "            Xc,yc = load_ctod_test(phase); pc = mdl.predict_proba(Xc)[:,1]\n",
    "            m05c = metrics_at_threshold(yc, pc, thr=0.5)\n",
    "            thr_c, _ = pick_threshold_balacc_max(yc, pc)\n",
    "            mtc = metrics_at_threshold(yc, pc, thr=thr_c)\n",
    "            df_ctod = summary_table_from(m05c, mtc, thr_c)\n",
    "\n",
    "            # HINT\n",
    "            Xh,yh = load_hint_test(phase); ph = mdl.predict_proba(Xh)[:,1]\n",
    "            m05h = metrics_at_threshold(yh, ph, thr=0.5)\n",
    "            thr_h, _ = pick_threshold_balacc_max(yh, ph)\n",
    "            mth = metrics_at_threshold(yh, ph, thr=thr_h)\n",
    "            df_hint = summary_table_from(m05h, mth, thr_h)\n",
    "\n",
    "            df_both = pd.concat({\"CTOD\": df_ctod, \"HINT\": df_hint}, axis=1)\n",
    "            out_csv = TAB_DIR / f\"quick_metrics_{phase}.csv\"\n",
    "            df_both.to_csv(out_csv)\n",
    "            out[phase] = out_csv\n",
    "        return out\n",
    "\n",
    "    qtbl_files = {k: str(v) for k, v in quick_metric_tables().items()}\n",
    "\n",
    "    print(\"==> Feature importance...\")\n",
    "    feature_importance_plots()\n",
    "    feature_importance_by_column()\n",
    "\n",
    "    print(\"==> Assembling HTML report...\")\n",
    "    build_html_report(df_ctod, df_hint, df_combined, qtbl_files)\n",
    "\n",
    "    print(\"\\n✅ Done. Abra: report/performance_report.html\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "_6kEEFj3IizZ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14417,
     "status": "ok",
     "timestamp": 1762515905413,
     "user": {
      "displayName": "Antonio Cortes",
      "userId": "07933854488654832685"
     },
     "user_tz": 0
    },
    "id": "_6kEEFj3IizZ",
    "outputId": "0f9e7b0b-7dcb-43fa-8d66-1c54b55ea43b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (pytrial311)",
   "language": "python",
   "name": "pytrial311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
